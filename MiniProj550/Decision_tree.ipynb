{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Building a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a skeleton of a decision tree classifier for the example data set in `data/example.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import median, mode, mean\n",
    "from collections import Counter\n",
    "from enum import Enum\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simple type definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttrType(Enum):\n",
    "    cat = 0  # categorical (qualitative) attribute\n",
    "    num = 1  # numerical (quantitative) attribute\n",
    "\n",
    "\n",
    "class NodeType(Enum):\n",
    "    internal = 1\n",
    "    root = 0\n",
    "    leaf = 2\n",
    "\n",
    "\n",
    "class SplitType(Enum):\n",
    "    bin = 0  # binary split\n",
    "    multi = 1  # multi-way split\n",
    "\n",
    "\n",
    "class OperatorType(Enum):\n",
    "    leq = 0  # Less than or equal to.. <=\n",
    "    gt = 1  # Greater Than... >\n",
    "    eq = 2 # Equal to =\n",
    " \n",
    "\n",
    "class Attribute(object):\n",
    "    def __init__(self, label, type,is_target,stat):\n",
    "        self.label = label\n",
    "        self.stat = stat  # holds mean for numerical and mode for categorical attributes\n",
    "        self.is_target = is_target\n",
    "        self.type = type\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.label}:{self.type}\"\n",
    "    \n",
    "    def __unicode__(self):\n",
    "        return f\"{self.label}:{self.type}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.label}:{self.type}\"\n",
    "\n",
    "\n",
    "class Splitting(object):\n",
    "    def __init__(self, attr, infogain, split_type, cond, splits):\n",
    "        self.attr = attr  # attribute ID (index in ATTR)\n",
    "        self.infogain = infogain  # information gain if splitting is done on this attribute\n",
    "        self.split_type = split_type  # one of SplitType\n",
    "        self.cond = cond  # splitting condition, i.e., values on outgoing edges\n",
    "        # list of training records (IDs) for each slitting condition\n",
    "        self.splits = splits\n",
    "\n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self, id, type,attr, parent_id, children=None, edge_value=None, val=None, split_type=None,operator_type = None, split_cond=None,\n",
    "                 infogain=None):\n",
    "        self.id = id  # ID (same as the index in DT.model list)\n",
    "        self.type = type  # one of NodeType\n",
    "        self.parent_id = parent_id  # ID of parent node (None if root)\n",
    "        self.children = children  # list of IDs of child nodes\n",
    "        self.attr = attr\n",
    "        self.operator_type = operator_type\n",
    "        # the value of the incoming edge (only if not root node)\n",
    "        self.edge_value = edge_value\n",
    "        self.val = val  # if root or internal node: the attribute that is compared at that node; if leaf node: the target value\n",
    "        self.split_type = split_type  # one of SplitType\n",
    "        # splitting condition (median value for binary splits on numerical values; otherwise a list of categorical values (corresponding to child nodes))\n",
    "        self.split_cond = split_cond\n",
    "        self.infogain = infogain\n",
    "        self.str = f\"id: {self.id}type:{self.type} EdgeValue:{self.edge_value}, Value={self.val} Type:{self.split_type} Conditions={self.split_cond} Gain:{self.infogain}\" \n",
    "\n",
    "    def operator_type_str(self):\n",
    "        if self.operator_type == OperatorType.leq:\n",
    "            return \"<=\"\n",
    "        if self.operator_type == OperatorType.gt:\n",
    "            return \">\"\n",
    "        if self.operator_type == OperatorType.eq:\n",
    "            return \"=\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.str\n",
    "    \n",
    "    def __unicode__(self):\n",
    "        return self.str\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.str\n",
    "\n",
    "    def append_child(self, node_id):\n",
    "        self.children.append(node_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, some basic classes to represent an attribute, a spltting procedure, and a node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input filename is hard-coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT(object):\n",
    "    def __init__(self, data,attributes,sampling_attr_size):\n",
    "        self.data = data  # training data set (loaded into memory)\n",
    "        self.model = None  # decision tree model\n",
    "        self.default_target = 0 # default target class\n",
    "        self.attributes = attributes\n",
    "        self.target_attribute = [x for x in self.attributes if  x.is_target ][0]\n",
    "        self.default_target = self.attributes.index(self.target_attribute)\n",
    "        self.sampling_attr_size = sampling_attr_size \n",
    "\n",
    "    def __subsampling_attributes(self,attrs):\n",
    "        attribute_length = len(attrs)\n",
    "        attr_indexes = np.random.choice(attribute_length,self.sampling_attr_size,replace=False).tolist()\n",
    "        #attr_indexes.append(attribute_length -1) #append target Node\n",
    "        return [attrs[i] for i in attr_indexes if i != attrs.index(self.target_attribute)]\n",
    "\n",
    "    def calculate_entropy(self,subset):\n",
    "        entropy = 0.0\n",
    "        sample_size = len(subset)\n",
    "        target_col = subset[self.target_attribute.label]\n",
    "        unique_vals = target_col.unique()\n",
    "        for unique_val in unique_vals:\n",
    "            unique_val_count = target_col[target_col == unique_val].count()\n",
    "            p_unique_val = unique_val_count / sample_size\n",
    "            entropy += -p_unique_val * math.log(p_unique_val,2)\n",
    "        return entropy\n",
    "\n",
    "    def calculate_gain(self,subset,attr):\n",
    "        entropy = self.calculate_entropy(subset)\n",
    "        sample_size = len(subset)\n",
    "        attr_col = subset[attr.label]\n",
    "        unique_vals = attr_col.unique()\n",
    "        for unique_val in unique_vals:\n",
    "            subset_data = subset[subset[attr.label] == unique_val]\n",
    "            entropy_val = self.calculate_entropy(subset_data)\n",
    "            unique_val_count = attr_col[attr_col == unique_val].count()\n",
    "            p_unique_val = unique_val_count / sample_size\n",
    "            entropy += -p_unique_val * entropy_val\n",
    "        return entropy\n",
    "\n",
    "\n",
    "    def __mean_squared_error(self, records):\n",
    "        \"\"\"\n",
    "        Calculates mean squared error for a selection of records.\n",
    "\n",
    "        :param records: Data records (given by indices)\n",
    "        \"\"\"\n",
    "        result = 0.0\n",
    "        if records.empty:\n",
    "            return result\n",
    "        mean = records.mean()\n",
    "        for record in records:\n",
    "            result += (record - mean)**2\n",
    "        return result/len(records)\n",
    "\n",
    "    def __find_best_attr(self,attrs, subset):\n",
    "        \"\"\"\n",
    "        Finds the attribute with the largest gain.\n",
    "        :param attrs: Set of attributes\n",
    "        :param subset: Training set (Pandas dataFrame with corresponding subset)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        #mse_p = self.__mean_squared_error(subset)  # parent's MSE\n",
    "        splittings = []  # holds the splitting information for each attribute\n",
    "        split_mode = None\n",
    "        for attr in attrs:\n",
    "            #attr_idx = attrs.index(attr)\n",
    "            splits = {}  # record IDs corresponding to each split\n",
    "            # splitting condition depends on the attribute type\n",
    "            if attr.is_target :# skip target attribute\n",
    "                continue\n",
    "            elif attr.type == AttrType.cat:  # categorical attribute, multi-way split on each possible value\n",
    "                split_mode = SplitType.multi\n",
    "                split_cond = subset[attr.label].unique()\n",
    "            elif attr.type == AttrType.num:  # numerical attribute => binary split on median value\n",
    "                split_mode = SplitType.bin\n",
    "                split_cond = subset[attr.label].median()\n",
    "                # unique_vals = self.data[attr.label].unique()\n",
    "                # unique_vals.sort()\n",
    "                # med_vals = {}\n",
    "                # for i in range(0,unique_vals.size,2):\n",
    "                #     med_val = (unique_vals[i] + unique_vals[i]) /2\n",
    "                #     ss = subset[ subset[attr.label] <= med_val]\n",
    "                #     gain = self.calculate_gain(ss, attr)\n",
    "                #     med_vals.update({med_val:gain})\n",
    "                \n",
    "                #split_cond = sorted(med_vals.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
    "                #print(f\"\\t best split cond is {split_cond}\")\n",
    "                #print(f\"\\t Calculating gain... {split_cond}\")\n",
    "                #split_cond = self.data.iloc[:,attr_idx].median()\n",
    "            infogain = self.calculate_gain(subset, attr)\n",
    "            splitting = Splitting(attr, infogain, split_mode, split_cond, splits)\n",
    "            splittings.append(splitting)\n",
    "\n",
    "        # find best splitting\n",
    "        best_splitting = sorted(splittings, key=lambda x: x.infogain, reverse=True)\n",
    "        return best_splitting[0]\n",
    "\n",
    "    def __add_node(self, parent_id,attr, node_type=NodeType.internal, edge_value=None, val=None, split_type=None,\n",
    "                   operator_type=None,split_cond=None):\n",
    "        \"\"\"\n",
    "        Adds a node to the decision tree.\n",
    "\n",
    "        :param parent_id:\n",
    "        :param node_type:opera\n",
    "        :param edge_value:\n",
    "        :param val:\n",
    "        :param split_type:\n",
    "        :param split_cond:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        node_id = len(self.model)  # id of the newly assigned node\n",
    "        if not self.model:  # the tree is empty\n",
    "            node_type = NodeType.root\n",
    "\n",
    "        node = Node(\n",
    "            node_id,\n",
    "            node_type,\n",
    "            attr, \n",
    "            parent_id, \n",
    "            children=[], \n",
    "            edge_value=edge_value, \n",
    "            val=val,\n",
    "            split_type=split_type,\n",
    "            operator_type=operator_type,\n",
    "            split_cond=split_cond)\n",
    "        self.model.append(node)\n",
    "\n",
    "        # also add it as a child of the parent node\n",
    "        if parent_id is not None:\n",
    "            self.model[parent_id].append_child(node_id)\n",
    "\n",
    "        return node_id\n",
    "    \n",
    "    def __id3(self, attrs,subset, parent_id=None, value=None,operator_type = None):\n",
    "        \"\"\"\n",
    "        Function ID3 that returns a decision tree.\n",
    "\n",
    "        :param attrs: Set of attributes\n",
    "        :param records: Training set (list of record ids)\n",
    "        :param parent_id: ID of parent node\n",
    "        :param value: Value corresponding to the parent attribute, i.e., label of the edge on which we arrived to this node\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        sample_attrs = attrs\n",
    "        #sample_attrs = self.__subsampling_attributes(attrs)\n",
    "\n",
    "        #print(f\"{subset.columns}\")\n",
    "\n",
    "        # empty training set or empty set of attributes => create leaf node with default class\n",
    "        if subset.empty or not sample_attrs or len(sample_attrs) == 0:\n",
    "            self.__add_node(parent_id,None, node_type=NodeType.leaf, edge_value=value, val=value,operator_type=operator_type)\n",
    "            return\n",
    "        # if all records have the same target value => create leaf node with that target value\n",
    "        if len(attrs)  == 1:\n",
    "            node_value = None\n",
    "            if self.target_attribute.type == AttrType.num:\n",
    "                node_value = subset[self.target_attribute.label].mean()\n",
    "            else :\n",
    "                uniquevals = subset[self.target_attribute.label].unique()\n",
    "                node_value = uniquevals\n",
    "            self.__add_node(parent_id,None, node_type=NodeType.leaf, edge_value=value, val=node_value,operator_type=operator_type)\n",
    "            return\n",
    "\n",
    "        # find the attribute with the largest gain\n",
    "        splitting = None\n",
    "        \n",
    "        # if not sample_attrs:\n",
    "        #     splitting = self.__find_best_attr(attrs, subset)\n",
    "        # else:\n",
    "        splitting = self.__find_best_attr(sample_attrs, subset)\n",
    "        \n",
    "        #print(f\"Best splitting attribute is {splitting.attr.label}\")\n",
    "        # add node\n",
    "        node_id = self.__add_node(parent_id,splitting.attr,node_type=NodeType.internal, edge_value=value, val=value, split_type=splitting.split_type,\n",
    "                                  split_cond=splitting.cond,operator_type=operator_type)\n",
    "        #Call tree construction recursively for each split\n",
    "        split_attrs = [x for x in attrs if x is not splitting.attr]\n",
    "        #print(split_attrs)\n",
    "        split_attr_idx = attrs.index(splitting.attr)\n",
    "        #print('New subset Splitting attributes',[x.label for x in split_attrs])\n",
    "        split_label = splitting.attr.label\n",
    "        if splitting.split_type == SplitType.bin:\n",
    "            ss1 = subset[ subset[split_label] <= splitting.cond]\n",
    "            ss1 = ss1.drop([split_label],axis=1)\n",
    "            ss2 = subset[ subset[split_label] > splitting.cond]\n",
    "            ss2 = ss2.drop(split_label,axis=1)\n",
    "            subset_value = round(subset[self.target_attribute.label].mean())\n",
    "            self.__id3(split_attrs,ss1,node_id,subset_value,operator_type=OperatorType.leq)\n",
    "            self.__id3(split_attrs,ss2,node_id,subset_value,operator_type=OperatorType.gt)\n",
    "        elif splitting.split_type  == SplitType.multi:\n",
    "            for split_cond in splitting.cond:\n",
    "                #print(f\"finding subset for category [{splitting.attr.label}-{split_cond}]\")\n",
    "                ss = subset[subset[split_label] == split_cond]\n",
    "                ss = ss.drop([split_label],axis=1)\n",
    "                subset_value = round(subset[self.target_attribute.label].mean())\n",
    "                self.__id3(split_attrs,ss,node_id,subset_value,operator_type=OperatorType.eq)\n",
    "        \n",
    "    def build_model(self):\n",
    "        self.model = []  # holds the decision tree model, represented as a list of nodes\n",
    "        self.__id3(self.attributes, self.data)\n",
    "\n",
    "    def apply_model(self, record):\n",
    "        node = self.model[0]\n",
    "        oldNode = None\n",
    "        while node.type != NodeType.leaf:\n",
    "            oldNode = node\n",
    "            #print(f\"\\t Applying DT model for  node {node.id}-{node.attr.label}-{node.split_cond}\")\n",
    "            attr = self.attributes.index(node.attr)\n",
    "            record_val = record[attr]\n",
    "            if node.split_type == SplitType.bin :\n",
    "                if record_val <= node.split_cond :\n",
    "                   node = self.model[ node.children[0] ]\n",
    "                else :\n",
    "                    node = self.model[ node.children[1] ]\n",
    "            if node.split_type == SplitType.multi : \n",
    "                for child_node_idx in node.children:\n",
    "                    child_node = self.model[child_node_idx]\n",
    "                    #print(f\"\\t Test {record_val} with {child_node.edge_value}\")\n",
    "                    if child_node.edge_value == record_val :\n",
    "                        node = child_node\n",
    "                        break\n",
    "            if oldNode == node:\n",
    "                break\n",
    "        print(node)\n",
    "        return node.val\n",
    "    \n",
    "    def predict(self, record):\n",
    "        prediction = self.apply_model(record)\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def print_model(self, node_id=0, level=0):\n",
    "        node = self.model[node_id]\n",
    "        indent = \"  \" * level\n",
    "        if node.type == NodeType.leaf:\n",
    "            print(indent + str(node.edge_value) + \" [Leaf node] class=\" + str(node.val))\n",
    "        else:\n",
    "            cond = f\" {node.operator_type_str()} \" + str(node.split_cond) if node.attr.type == AttrType.num else f\" {node.operator_type_str()} ? \"\n",
    "            if node.type == NodeType.root:\n",
    "                print(\"[Root node] '\" + node.attr.label + \"'\" + cond)\n",
    "            else:\n",
    "                print(indent + str(node.edge_value) + \" [Internal node] '\" + node.attr.label + \"'\" + cond)\n",
    "            # print tree for child notes recursively\n",
    "            for n_id in node.children:\n",
    "                self.print_model(n_id, level + 1)\n",
    "\n",
    "class RF(object):\n",
    "    def __init__(self,data):\n",
    "        self.data = data  # training data set (loaded into memory)\n",
    "        self.forest = [] # decision trees\n",
    "        self.attributes =[]\n",
    "        self.MAX_CATEGORY_SIZE = 20\n",
    "       \n",
    "        col_length = len(self.data.columns) \n",
    "        for col_idx in range(col_length):\n",
    "            col = self.data.columns[col_idx]\n",
    "            attr_type = AttrType.num\n",
    "            stat = data.mean()\n",
    "            #Lets consider a max number of minimum values = 20 to classify the attribute as Categorical \n",
    "            colUniqueLen = len(data[col].unique())\n",
    "            if colUniqueLen <= self.MAX_CATEGORY_SIZE:\n",
    "                attr_type = AttrType.cat\n",
    "                stat = data.mode()\n",
    "            is_target = col_idx == col_length - 1 \n",
    "            attr = Attribute(col,attr_type,is_target,stat)\n",
    "            self.attributes.append(attr)\n",
    "             \n",
    "\n",
    "    def __subsampling(self, data, sample_size_ratio):\n",
    "        data_length = len(data)\n",
    "        sample_number = round(data_length * sample_size_ratio)\n",
    "        sample_indexes = np.random.randint(low=0,high= data_length, size=sample_number)\n",
    "        subsample  = data.iloc[sample_indexes,:]\n",
    "        return subsample\n",
    "        \n",
    "    def build_model(self,number_of_trees=1, sample_size_ratio=None,sample_attr_size=None):\n",
    "        for i in range(number_of_trees):\n",
    "            print(f'Creating tree # {i}...')\n",
    "            print(f'\\t Subsampling...')\n",
    "            sample = self.data\n",
    "            if number_of_trees > 1 or not sample_size_ratio is None:\n",
    "                sample = self.__subsampling(self.data, sample_size_ratio)\n",
    "            \n",
    "            print(f'\\t Initializing...')\n",
    "            tree = DT(sample,self.attributes,sample_attr_size) \n",
    "            print(f'\\t Modelling...')\n",
    "            tree.build_model()\n",
    "            self.forest.append(tree)\n",
    "            print(f'\\t Model completed')\n",
    "            \n",
    "    def predict(self, test_data):\n",
    "        rf_predictions = pd.DataFrame(columns=['Id','SalePrice'])\n",
    "        rf_predictions.astype({'Id': 'int32'}).dtypes\n",
    "        n = test_data.shape[0]\n",
    "        print(f\"Starting predictions ({n})...\")\n",
    "        for row_idx in range(n):\n",
    "            row = test_data.iloc[row_idx,:]\n",
    "            predictions = []\n",
    "            forest_length = len(self.forest)\n",
    "            predictions = np.zeros(forest_length)\n",
    "            for tree_idx in range(forest_length):\n",
    "                tree = self.forest[tree_idx]\n",
    "                prediction = tree.predict(row) \n",
    "                predictions[tree_idx] = prediction\n",
    "                result = predictions.mean()\n",
    "            rf_predictions = rf_predictions.append({'Id':row_idx,'SalePrice':result},ignore_index=True)\n",
    "            print(f\"{row_idx} of {n} = {result}\")\n",
    "        return rf_predictions\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute labels types are hard-coded too (the same order as in the file!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_vals(data):\n",
    "    for col in data.columns :\n",
    "        if data[col].dtype == 'object' :\n",
    "            data[col] = data[col].str.strip()\n",
    "            data[col] = data[col].fillna('NA')\n",
    "    #After a quuick check nulll data was found           \n",
    "    # x=data.isna()\n",
    "    # x = x.sum()\n",
    "    # y = x[x > 0].sort_values()\n",
    "    # types = data[y.keys()].dtypes\n",
    "    # The rest of the values consider NA as an acceptable category, for these it will be\n",
    "    # Necessary to fill the nulls\n",
    "    null_cols = ['Electrical','MasVnrArea','GarageYrBlt','LotFrontage']\n",
    "    for col in null_cols:\n",
    "        data_col = data[col]\n",
    "        null_rows = data_col.isnull() \n",
    "        non_nulls = data_col[null_rows == False]\n",
    "        mean_val = None\n",
    "        if data[col].dtype == 'object':\n",
    "            mean_val = non_nulls.value_counts().keys()[0]\n",
    "        else:\n",
    "            mean_val = non_nulls.mean()\n",
    "        data[col].fillna(mean_val,inplace=True)\n",
    "\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object':\n",
    "            data[col] = data[col].astype('category')\n",
    "            data[col]  = data[col].cat.codes\n",
    "\n",
    "def load_train_data(file_name,plot=False):\n",
    "    data = pd.read_csv(file_name)\n",
    "    fill_missing_vals(data)\n",
    "    data_d = data.describe()\n",
    "    ## Finding columns with the mayority of values = to 0\n",
    "    zero_features = data_d.iloc[6,:] == 0\n",
    "    filtered_zero_features = zero_features[zero_features]\n",
    "    data.drop(filtered_zero_features.keys(),axis=1, inplace=True)\n",
    "    if plot:\n",
    "        data.hist(figsize=(20,20), bins=20)\n",
    "        plt.show()\n",
    "    corr = data.corr()\n",
    "    corr_values = corr['SalePrice'].sort_values(ascending=False)\n",
    "    if plot:\n",
    "        fig,ax = plt.subplots(figsize=(12,9))\n",
    "        sns.heatmap(corr,vmax=.8,square=True)\n",
    "    ##Let's consider now correlation values above 0.3, which is a good value representing correlation\n",
    "    good_correlation = corr_values > 0.3\n",
    "    feature_values = good_correlation[good_correlation]\n",
    "    drop_columns = [c for c in  data.columns if c not in feature_values  ]\n",
    "    data.drop(drop_columns,axis=1, inplace=True)\n",
    "    corr = data.corr()\n",
    "    corr_values = corr['SalePrice'].sort_values(ascending=False)\n",
    "    if plot :\n",
    "        sns.set(font_scale=1.25)\n",
    "        fig,ax = plt.subplots(figsize=(12,9))\n",
    "        sns.heatmap(corr,vmax=.8,square=True,annot=True)\n",
    "   \n",
    "    return data\n",
    "    # fig,ax = plt.subplots(figsize=(12,9))\n",
    "    # sns.heatmap(corr,vmax=.8,square=True)\n",
    "\n",
    "def load_test_data(file_name,keep_cols):\n",
    "    test_data = pd.read_csv(file_name)\n",
    "    data_cols = test_data.columns\n",
    "    drop_cols = [col for col in data_cols if col not in keep_cols]\n",
    "    fill_missing_vals(test_data)\n",
    "    test_data.drop(drop_cols,axis=1, inplace=True)\n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the main function building a decision tree model, printing it and applying it on some unseen records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ".0, Value=148725.0 Type:SplitType.multi Conditions=[0 1 2] Gain:None\n1416 of 1560 = 148725.0\nid: 11460type:NodeType.internal EdgeValue:146865.0, Value=146865.0 Type:SplitType.multi Conditions=[8 6 7 9] Gain:None\n1417 of 1560 = 146865.0\nid: 11693type:NodeType.internal EdgeValue:155417.0, Value=155417.0 Type:SplitType.multi Conditions=[5 6 7] Gain:None\n1418 of 1560 = 155417.0\nid: 2706type:NodeType.internal EdgeValue:118333.0, Value=118333.0 Type:SplitType.multi Conditions=[1 0] Gain:None\n1419 of 1560 = 118333.0\nid: 11460type:NodeType.internal EdgeValue:146865.0, Value=146865.0 Type:SplitType.multi Conditions=[8 6 7 9] Gain:None\n1420 of 1560 = 146865.0\nid: 11693type:NodeType.internal EdgeValue:155417.0, Value=155417.0 Type:SplitType.multi Conditions=[5 6 7] Gain:None\n1421 of 1560 = 155417.0\nid: 12086type:NodeType.internal EdgeValue:170883.0, Value=170883.0 Type:SplitType.multi Conditions=[6 8 7] Gain:None\n1422 of 1560 = 170883.0\nid: 10470type:NodeType.internal EdgeValue:214833.0, Value=214833.0 Type:SplitType.multi Conditions=[7 6] Gain:None\n1423 of 1560 = 214833.0\nid: 10470type:NodeType.internal EdgeValue:214833.0, Value=214833.0 Type:SplitType.multi Conditions=[7 6] Gain:None\n1424 of 1560 = 214833.0\nid: 15216type:NodeType.internal EdgeValue:153000.0, Value=153000.0 Type:SplitType.multi Conditions=[2 1] Gain:None\n1425 of 1560 = 153000.0\nid: 2605type:NodeType.internal EdgeValue:112036.0, Value=112036.0 Type:SplitType.multi Conditions=[5 6 3] Gain:None\n1426 of 1560 = 112036.0\nid: 2955type:NodeType.internal EdgeValue:107967.0, Value=107967.0 Type:SplitType.multi Conditions=[5 4 7 6] Gain:None\n1427 of 1560 = 107967.0\nid: 859type:NodeType.internal EdgeValue:84709.0, Value=84709.0 Type:SplitType.multi Conditions=[5 6 1 4 3] Gain:None\n1428 of 1560 = 84709.0\nid: 354type:NodeType.internal EdgeValue:89275.0, Value=89275.0 Type:SplitType.multi Conditions=[6 4 5] Gain:None\n1429 of 1560 = 89275.0\nid: 11845type:NodeType.internal EdgeValue:137467.0, Value=137467.0 Type:SplitType.multi Conditions=[5] Gain:None\n1430 of 1560 = 137467.0\nid: 859type:NodeType.internal EdgeValue:84709.0, Value=84709.0 Type:SplitType.multi Conditions=[5 6 1 4 3] Gain:None\n1431 of 1560 = 84709.0\nid: 5295type:NodeType.internal EdgeValue:96313.0, Value=96313.0 Type:SplitType.multi Conditions=[1 0 3] Gain:None\n1432 of 1560 = 96313.0\nid: 1077type:NodeType.internal EdgeValue:78300.0, Value=78300.0 Type:SplitType.multi Conditions=[6 4 7] Gain:None\n1433 of 1560 = 78300.0\nid: 18646type:NodeType.internal EdgeValue:354885.0, Value=354885.0 Type:SplitType.multi Conditions=[8 9] Gain:None\n1434 of 1560 = 354885.0\nid: 18646type:NodeType.internal EdgeValue:354885.0, Value=354885.0 Type:SplitType.multi Conditions=[8 9] Gain:None\n1435 of 1560 = 354885.0\nid: 17853type:NodeType.internal EdgeValue:210580.0, Value=210580.0 Type:SplitType.multi Conditions=[8 5 6] Gain:None\n1436 of 1560 = 210580.0\nid: 17782type:NodeType.internal EdgeValue:206500.0, Value=206500.0 Type:SplitType.multi Conditions=[5 7 6] Gain:None\n1437 of 1560 = 206500.0\nid: 16116type:NodeType.internal EdgeValue:219233.0, Value=219233.0 Type:SplitType.multi Conditions=[7 8] Gain:None\n1438 of 1560 = 219233.0\nid: 9095type:NodeType.internal EdgeValue:168933.0, Value=168933.0 Type:SplitType.multi Conditions=[5] Gain:None\n1439 of 1560 = 168933.0\nid: 17615type:NodeType.internal EdgeValue:140450.0, Value=140450.0 Type:SplitType.multi Conditions=[5] Gain:None\n1440 of 1560 = 140450.0\nid: 8877type:NodeType.internal EdgeValue:183333.0, Value=183333.0 Type:SplitType.multi Conditions=[7] Gain:None\n1441 of 1560 = 183333.0\nid: 19113type:NodeType.internal EdgeValue:301488.0, Value=301488.0 Type:SplitType.multi Conditions=[8 9] Gain:None\n1442 of 1560 = 301488.0\nid: 18684type:NodeType.internal EdgeValue:375331.0, Value=375331.0 Type:SplitType.multi Conditions=[10  8] Gain:None\n1443 of 1560 = 375331.0\nid: 15146type:NodeType.internal EdgeValue:147000.0, Value=147000.0 Type:SplitType.multi Conditions=[6 5] Gain:None\n1444 of 1560 = 147000.0\nid: 9887type:NodeType.internal EdgeValue:186050.0, Value=186050.0 Type:SplitType.multi Conditions=[7 5] Gain:None\n1445 of 1560 = 186050.0\nid: 1818type:NodeType.internal EdgeValue:132997.0, Value=132997.0 Type:SplitType.multi Conditions=[6 5] Gain:None\n1446 of 1560 = 132997.0\nid: 4220type:NodeType.internal EdgeValue:127250.0, Value=127250.0 Type:SplitType.multi Conditions=[6 4 5] Gain:None\n1447 of 1560 = 127250.0\nid: 18866type:NodeType.internal EdgeValue:238967.0, Value=238967.0 Type:SplitType.multi Conditions=[7 8] Gain:None\n1448 of 1560 = 238967.0\nid: 1859type:NodeType.internal EdgeValue:88000.0, Value=88000.0 Type:SplitType.multi Conditions=[4 5] Gain:None\n1449 of 1560 = 88000.0\nid: 1550type:NodeType.internal EdgeValue:122000.0, Value=122000.0 Type:SplitType.multi Conditions=[3 1] Gain:None\n1450 of 1560 = 122000.0\nid: 5764type:NodeType.internal EdgeValue:138950.0, Value=138950.0 Type:SplitType.multi Conditions=[2 1] Gain:None\n1451 of 1560 = 138950.0\nid: 1411type:NodeType.internal EdgeValue:81044.0, Value=81044.0 Type:SplitType.multi Conditions=[4 6 3] Gain:None\n1452 of 1560 = 81044.0\nid: 1735type:NodeType.internal EdgeValue:103167.0, Value=103167.0 Type:SplitType.multi Conditions=[5 6] Gain:None\n1453 of 1560 = 103167.0\nid: 1735type:NodeType.internal EdgeValue:103167.0, Value=103167.0 Type:SplitType.multi Conditions=[5 6] Gain:None\n1454 of 1560 = 103167.0\nid: 1411type:NodeType.internal EdgeValue:81044.0, Value=81044.0 Type:SplitType.multi Conditions=[4 6 3] Gain:None\n1455 of 1560 = 81044.0\nid: 9709type:NodeType.internal EdgeValue:172500.0, Value=172500.0 Type:SplitType.multi Conditions=[6 5] Gain:None\n1456 of 1560 = 172500.0\nid: 3777type:NodeType.internal EdgeValue:121875.0, Value=121875.0 Type:SplitType.multi Conditions=[6 5] Gain:None\n1457 of 1560 = 121875.0\nid: 14488type:NodeType.internal EdgeValue:278500.0, Value=278500.0 Type:SplitType.multi Conditions=[7] Gain:None\n1458 of 1560 = 278500.0\nid: 6636type:NodeType.internal EdgeValue:138246.0, Value=138246.0 Type:SplitType.multi Conditions=[6 4 5] Gain:None\n1459 of 1560 = 138246.0\nid: 6240type:NodeType.internal EdgeValue:145000.0, Value=145000.0 Type:SplitType.multi Conditions=[7 5 4] Gain:None\n1460 of 1560 = 145000.0\nid: 19335type:NodeType.internal EdgeValue:351291.0, Value=351291.0 Type:SplitType.multi Conditions=[8] Gain:None\n1461 of 1560 = 351291.0\nid: 3330type:NodeType.internal EdgeValue:121458.0, Value=121458.0 Type:SplitType.multi Conditions=[5 4 8] Gain:None\n1462 of 1560 = 121458.0\nid: 10672type:NodeType.internal EdgeValue:154100.0, Value=154100.0 Type:SplitType.multi Conditions=[7 5 6] Gain:None\n1463 of 1560 = 154100.0\nid: 4303type:NodeType.internal EdgeValue:138833.0, Value=138833.0 Type:SplitType.multi Conditions=[4 5] Gain:None\n1464 of 1560 = 138833.0\nid: 2744type:NodeType.internal EdgeValue:126992.0, Value=126992.0 Type:SplitType.multi Conditions=[5 7 6] Gain:None\n1465 of 1560 = 126992.0\nid: 2872type:NodeType.internal EdgeValue:105733.0, Value=105733.0 Type:SplitType.multi Conditions=[4 5] Gain:None\n1466 of 1560 = 105733.0\nid: 8826type:NodeType.internal EdgeValue:204925.0, Value=204925.0 Type:SplitType.multi Conditions=[7] Gain:None\n1467 of 1560 = 204925.0\nid: 11251type:NodeType.internal EdgeValue:187567.0, Value=187567.0 Type:SplitType.multi Conditions=[7 6 5] Gain:None\n1468 of 1560 = 187567.0\nid: 6038type:NodeType.internal EdgeValue:146150.0, Value=146150.0 Type:SplitType.multi Conditions=[5 6] Gain:None\n1469 of 1560 = 146150.0\nid: 15992type:NodeType.internal EdgeValue:222375.0, Value=222375.0 Type:SplitType.multi Conditions=[9 8 5 6 7] Gain:None\n1470 of 1560 = 222375.0\nid: 10510type:NodeType.internal EdgeValue:148967.0, Value=148967.0 Type:SplitType.multi Conditions=[5 6] Gain:None\n1471 of 1560 = 148967.0\nid: 4063type:NodeType.internal EdgeValue:125767.0, Value=125767.0 Type:SplitType.multi Conditions=[1 0] Gain:None\n1472 of 1560 = 125767.0\nid: 477type:NodeType.internal EdgeValue:103433.0, Value=103433.0 Type:SplitType.multi Conditions=[5 2 4] Gain:None\n1473 of 1560 = 103433.0\nid: 17273type:NodeType.internal EdgeValue:265034.0, Value=265034.0 Type:SplitType.multi Conditions=[7 8] Gain:None\n1474 of 1560 = 265034.0\nid: 10385type:NodeType.internal EdgeValue:130833.0, Value=130833.0 Type:SplitType.multi Conditions=[2 1] Gain:None\n1475 of 1560 = 130833.0\nid: 15090type:NodeType.internal EdgeValue:147000.0, Value=147000.0 Type:SplitType.multi Conditions=[5 3 6] Gain:None\n1476 of 1560 = 147000.0\nid: 9945type:NodeType.internal EdgeValue:204091.0, Value=204091.0 Type:SplitType.multi Conditions=[6 7 8] Gain:None\n1477 of 1560 = 204091.0\nid: 12623type:NodeType.internal EdgeValue:151333.0, Value=151333.0 Type:SplitType.multi Conditions=[7] Gain:None\n1478 of 1560 = 151333.0\nid: 1935type:NodeType.internal EdgeValue:137330.0, Value=137330.0 Type:SplitType.multi Conditions=[6 7 5] Gain:None\n1479 of 1560 = 137330.0\nid: 3964type:NodeType.internal EdgeValue:117071.0, Value=117071.0 Type:SplitType.multi Conditions=[1 0] Gain:None\n1480 of 1560 = 117071.0\nid: 8426type:NodeType.internal EdgeValue:160650.0, Value=160650.0 Type:SplitType.multi Conditions=[5 7 6] Gain:None\n1481 of 1560 = 160650.0\nid: 19942type:NodeType.internal EdgeValue:374175.0, Value=374175.0 Type:SplitType.multi Conditions=[ 6  8 11 12] Gain:None\n1482 of 1560 = 374175.0\nid: 5464type:NodeType.internal EdgeValue:129157.0, Value=129157.0 Type:SplitType.multi Conditions=[5 6 4] Gain:None\n1483 of 1560 = 129157.0\nid: 9642type:NodeType.internal EdgeValue:141967.0, Value=141967.0 Type:SplitType.multi Conditions=[1 2] Gain:None\n1484 of 1560 = 141967.0\nid: 19592type:NodeType.internal EdgeValue:345450.0, Value=345450.0 Type:SplitType.multi Conditions=[8] Gain:None\n1485 of 1560 = 345450.0\nid: 4264type:NodeType.internal EdgeValue:129000.0, Value=129000.0 Type:SplitType.multi Conditions=[5 6] Gain:None\n1486 of 1560 = 129000.0\nid: 15308type:NodeType.internal EdgeValue:177868.0, Value=177868.0 Type:SplitType.multi Conditions=[1 4] Gain:None\n1487 of 1560 = 177868.0\nid: 2231type:NodeType.internal EdgeValue:163480.0, Value=163480.0 Type:SplitType.multi Conditions=[7 5] Gain:None\n1488 of 1560 = 163480.0\nid: 6993type:NodeType.internal EdgeValue:154700.0, Value=154700.0 Type:SplitType.multi Conditions=[6 7] Gain:None\n1489 of 1560 = 154700.0\nid: 6871type:NodeType.internal EdgeValue:145433.0, Value=145433.0 Type:SplitType.multi Conditions=[4 5 6] Gain:None\n1490 of 1560 = 145433.0\nid: 19605type:NodeType.internal EdgeValue:349403.0, Value=349403.0 Type:SplitType.multi Conditions=[9 8] Gain:None\n1491 of 1560 = 349403.0\nid: 14945type:NodeType.internal EdgeValue:271000.0, Value=271000.0 Type:SplitType.multi Conditions=[7 8] Gain:None\n1492 of 1560 = 271000.0\nid: 16514type:NodeType.internal EdgeValue:209945.0, Value=209945.0 Type:SplitType.multi Conditions=[10  5  6  9  7] Gain:None\n1493 of 1560 = 209945.0\nid: 7517type:NodeType.internal EdgeValue:152400.0, Value=152400.0 Type:SplitType.multi Conditions=[6 5] Gain:None\n1494 of 1560 = 152400.0\nid: 18241type:NodeType.internal EdgeValue:229502.0, Value=229502.0 Type:SplitType.multi Conditions=[10  8  9  7] Gain:None\n1495 of 1560 = 229502.0\nid: 18458type:NodeType.internal EdgeValue:199500.0, Value=199500.0 Type:SplitType.multi Conditions=[6] Gain:None\n1496 of 1560 = 199500.0\nid: 17067type:NodeType.internal EdgeValue:279105.0, Value=279105.0 Type:SplitType.multi Conditions=[7 8 9] Gain:None\n1497 of 1560 = 279105.0\nid: 6740type:NodeType.internal EdgeValue:132000.0, Value=132000.0 Type:SplitType.multi Conditions=[5 6] Gain:None\n1498 of 1560 = 132000.0\nid: 14552type:NodeType.internal EdgeValue:252950.0, Value=252950.0 Type:SplitType.multi Conditions=[8] Gain:None\n1499 of 1560 = 252950.0\nid: 11460type:NodeType.internal EdgeValue:146865.0, Value=146865.0 Type:SplitType.multi Conditions=[8 6 7 9] Gain:None\n1500 of 1560 = 146865.0\nid: 18421type:NodeType.internal EdgeValue:232000.0, Value=232000.0 Type:SplitType.multi Conditions=[6 8] Gain:None\n1501 of 1560 = 232000.0\nid: 9848type:NodeType.internal EdgeValue:280167.0, Value=280167.0 Type:SplitType.multi Conditions=[8 7] Gain:None\n1502 of 1560 = 280167.0\nid: 13141type:NodeType.internal EdgeValue:216793.0, Value=216793.0 Type:SplitType.multi Conditions=[6 8 7 9] Gain:None\n1503 of 1560 = 216793.0\nid: 3415type:NodeType.internal EdgeValue:112300.0, Value=112300.0 Type:SplitType.multi Conditions=[5] Gain:None\n1504 of 1560 = 112300.0\nid: 3109type:NodeType.internal EdgeValue:117483.0, Value=117483.0 Type:SplitType.multi Conditions=[4 5] Gain:None\n1505 of 1560 = 117483.0\nid: 11820type:NodeType.internal EdgeValue:137467.0, Value=137467.0 Type:SplitType.multi Conditions=[6 5] Gain:None\n1506 of 1560 = 137467.0\nid: 18847type:NodeType.internal EdgeValue:365439.0, Value=365439.0 Type:SplitType.multi Conditions=[9] Gain:None\n1507 of 1560 = 365439.0\nid: 13853type:NodeType.internal EdgeValue:192957.0, Value=192957.0 Type:SplitType.multi Conditions=[6 5 7] Gain:None\n1508 of 1560 = 192957.0\nid: 12826type:NodeType.internal EdgeValue:223000.0, Value=223000.0 Type:SplitType.multi Conditions=[7] Gain:None\n1509 of 1560 = 223000.0\nid: 10079type:NodeType.internal EdgeValue:148725.0, Value=148725.0 Type:SplitType.multi Conditions=[0 1 2] Gain:None\n1510 of 1560 = 148725.0\nid: 12320type:NodeType.internal EdgeValue:176333.0, Value=176333.0 Type:SplitType.multi Conditions=[6 7] Gain:None\n1511 of 1560 = 176333.0\nid: 17003type:NodeType.internal EdgeValue:198826.0, Value=198826.0 Type:SplitType.multi Conditions=[7] Gain:None\n1512 of 1560 = 198826.0\nid: 19705type:NodeType.internal EdgeValue:396449.0, Value=396449.0 Type:SplitType.multi Conditions=[9] Gain:None\n1513 of 1560 = 396449.0\nid: 9084type:NodeType.internal EdgeValue:163450.0, Value=163450.0 Type:SplitType.multi Conditions=[6] Gain:None\n1514 of 1560 = 163450.0\nid: 11208type:NodeType.internal EdgeValue:187567.0, Value=187567.0 Type:SplitType.multi Conditions=[6 5 7] Gain:None\n1515 of 1560 = 187567.0\nid: 6636type:NodeType.internal EdgeValue:138246.0, Value=138246.0 Type:SplitType.multi Conditions=[6 4 5] Gain:None\n1516 of 1560 = 138246.0\nid: 18241type:NodeType.internal EdgeValue:229502.0, Value=229502.0 Type:SplitType.multi Conditions=[10  8  9  7] Gain:None\n1517 of 1560 = 229502.0\nid: 19890type:NodeType.internal EdgeValue:319062.0, Value=319062.0 Type:SplitType.multi Conditions=[8] Gain:None\n1518 of 1560 = 319062.0\nid: 13773type:NodeType.internal EdgeValue:224728.0, Value=224728.0 Type:SplitType.multi Conditions=[8 7 6] Gain:None\n1519 of 1560 = 224728.0\nid: 19113type:NodeType.internal EdgeValue:301488.0, Value=301488.0 Type:SplitType.multi Conditions=[8 9] Gain:None\n1520 of 1560 = 301488.0\nid: 1357type:NodeType.internal EdgeValue:81044.0, Value=81044.0 Type:SplitType.multi Conditions=[5 4 2] Gain:None\n1521 of 1560 = 81044.0\nid: 7961type:NodeType.internal EdgeValue:193921.0, Value=193921.0 Type:SplitType.multi Conditions=[8 6] Gain:None\n1522 of 1560 = 193921.0\nid: 354type:NodeType.internal EdgeValue:89275.0, Value=89275.0 Type:SplitType.multi Conditions=[6 4 5] Gain:None\n1523 of 1560 = 89275.0\nid: 2201type:NodeType.internal EdgeValue:153457.0, Value=153457.0 Type:SplitType.multi Conditions=[7 6] Gain:None\n1524 of 1560 = 153457.0\nid: 4544type:NodeType.internal EdgeValue:114488.0, Value=114488.0 Type:SplitType.multi Conditions=[4 5 6] Gain:None\n1525 of 1560 = 114488.0\nid: 10019type:NodeType.internal EdgeValue:226274.0, Value=226274.0 Type:SplitType.multi Conditions=[7 6] Gain:None\n1526 of 1560 = 226274.0\nid: 11889type:NodeType.internal EdgeValue:143000.0, Value=143000.0 Type:SplitType.multi Conditions=[2 1] Gain:None\n1527 of 1560 = 143000.0\nid: 10type:NodeType.internal EdgeValue:98167.0, Value=98167.0 Type:SplitType.multi Conditions=[4 5] Gain:None\n1528 of 1560 = 98167.0\nid: 7992type:NodeType.internal EdgeValue:140425.0, Value=140425.0 Type:SplitType.multi Conditions=[7 6 5 8] Gain:None\n1529 of 1560 = 140425.0\nid: 18389type:NodeType.internal EdgeValue:237150.0, Value=237150.0 Type:SplitType.multi Conditions=[7 8] Gain:None\n1530 of 1560 = 237150.0\nid: 13473type:NodeType.internal EdgeValue:203250.0, Value=203250.0 Type:SplitType.multi Conditions=[7] Gain:None\n1531 of 1560 = 203250.0\nid: 7381type:NodeType.internal EdgeValue:158900.0, Value=158900.0 Type:SplitType.multi Conditions=[5 6] Gain:None\n1532 of 1560 = 158900.0\nid: 6223type:NodeType.internal EdgeValue:123274.0, Value=123274.0 Type:SplitType.multi Conditions=[5] Gain:None\n1533 of 1560 = 123274.0\nid: 4612type:NodeType.internal EdgeValue:114488.0, Value=114488.0 Type:SplitType.multi Conditions=[4 5] Gain:None\n1534 of 1560 = 114488.0\nid: 9147type:NodeType.internal EdgeValue:172000.0, Value=172000.0 Type:SplitType.multi Conditions=[6 7] Gain:None\n1535 of 1560 = 172000.0\nid: 15992type:NodeType.internal EdgeValue:222375.0, Value=222375.0 Type:SplitType.multi Conditions=[9 8 5 6 7] Gain:None\n1536 of 1560 = 222375.0\nid: 14394type:NodeType.internal EdgeValue:222500.0, Value=222500.0 Type:SplitType.multi Conditions=[7] Gain:None\n1537 of 1560 = 222500.0\nid: 1282type:NodeType.internal EdgeValue:128780.0, Value=128780.0 Type:SplitType.multi Conditions=[5 6 3] Gain:None\n1538 of 1560 = 128780.0\nid: 14251type:NodeType.internal EdgeValue:235333.0, Value=235333.0 Type:SplitType.multi Conditions=[8 7] Gain:None\n1539 of 1560 = 235333.0\nid: 11820type:NodeType.internal EdgeValue:137467.0, Value=137467.0 Type:SplitType.multi Conditions=[6 5] Gain:None\n1540 of 1560 = 137467.0\nid: 3995type:NodeType.internal EdgeValue:122133.0, Value=122133.0 Type:SplitType.multi Conditions=[5] Gain:None\n1541 of 1560 = 122133.0\nid: 7406type:NodeType.internal EdgeValue:158900.0, Value=158900.0 Type:SplitType.multi Conditions=[5] Gain:None\n1542 of 1560 = 158900.0\nid: 11613type:NodeType.internal EdgeValue:141314.0, Value=141314.0 Type:SplitType.multi Conditions=[6 7] Gain:None\n1543 of 1560 = 141314.0\nid: 4819type:NodeType.internal EdgeValue:118650.0, Value=118650.0 Type:SplitType.multi Conditions=[4 5] Gain:None\n1544 of 1560 = 118650.0\nid: 15949type:NodeType.internal EdgeValue:231250.0, Value=231250.0 Type:SplitType.multi Conditions=[8 5 7] Gain:None\n1545 of 1560 = 231250.0\nid: 5796type:NodeType.internal EdgeValue:116165.0, Value=116165.0 Type:SplitType.multi Conditions=[4 5 7 6] Gain:None\n1546 of 1560 = 116165.0\nid: 3330type:NodeType.internal EdgeValue:121458.0, Value=121458.0 Type:SplitType.multi Conditions=[5 4 8] Gain:None\n1547 of 1560 = 121458.0\nid: 18241type:NodeType.internal EdgeValue:229502.0, Value=229502.0 Type:SplitType.multi Conditions=[10  8  9  7] Gain:None\n1548 of 1560 = 229502.0\nid: 15216type:NodeType.internal EdgeValue:153000.0, Value=153000.0 Type:SplitType.multi Conditions=[2 1] Gain:None\n1549 of 1560 = 153000.0\nid: 14755type:NodeType.internal EdgeValue:289700.0, Value=289700.0 Type:SplitType.multi Conditions=[9 8] Gain:None\n1550 of 1560 = 289700.0\nid: 589type:NodeType.internal EdgeValue:114511.0, Value=114511.0 Type:SplitType.multi Conditions=[5 7 6] Gain:None\n1551 of 1560 = 114511.0\nid: 17445type:NodeType.internal EdgeValue:325500.0, Value=325500.0 Type:SplitType.multi Conditions=[8] Gain:None\n1552 of 1560 = 325500.0\nid: 6636type:NodeType.internal EdgeValue:138246.0, Value=138246.0 Type:SplitType.multi Conditions=[6 4 5] Gain:None\n1553 of 1560 = 138246.0\nid: 16514type:NodeType.internal EdgeValue:209945.0, Value=209945.0 Type:SplitType.multi Conditions=[10  5  6  9  7] Gain:None\n1554 of 1560 = 209945.0\nid: 16116type:NodeType.internal EdgeValue:219233.0, Value=219233.0 Type:SplitType.multi Conditions=[7 8] Gain:None\n1555 of 1560 = 219233.0\nid: 6038type:NodeType.internal EdgeValue:146150.0, Value=146150.0 Type:SplitType.multi Conditions=[5 6] Gain:None\n1556 of 1560 = 146150.0\nid: 2186type:NodeType.internal EdgeValue:153457.0, Value=153457.0 Type:SplitType.multi Conditions=[7] Gain:None\n1557 of 1560 = 153457.0\nid: 16721type:NodeType.internal EdgeValue:208250.0, Value=208250.0 Type:SplitType.multi Conditions=[ 7 11  6] Gain:None\n1558 of 1560 = 208250.0\nid: 522type:NodeType.internal EdgeValue:114511.0, Value=114511.0 Type:SplitType.multi Conditions=[4 5 6] Gain:None\n1559 of 1560 = 114511.0\n"
    },
    {
     "ename": "NameError",
     "evalue": "name 'createSubmission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0e5d1deaa0d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcreateSubmission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-0e5d1deaa0d6>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtest_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mcreateSubmission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'createSubmission' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    train_file_name = \"data\\housing_price_train.csv\"\n",
    "    test_file_name = \"data\\housing_price_test.csv\"\n",
    "    train_data = load_train_data(train_file_name)\n",
    "    test_data = load_test_data(test_file_name,train_data.columns) \n",
    "    #%%\n",
    "    rf = RF(train_data)\n",
    "    rf.build_model()\n",
    "    test_results = rf.predict(test_data)\n",
    "    createSubmission(test_results)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}