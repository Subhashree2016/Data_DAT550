{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit Learn\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "documents = [\r\n",
    "    \"Unlike classification or prediction, which analyzes data objects with class labels, clustering analyzes data objects without consulting a known class label. The class labels are not in the data  because they are not known.\",\r\n",
    "    \"Classification can be used for prediction of class labels of data objects. However, in many applications, prediction of missing or not known data values rather than class labels is performed to fit  data objects into a schema.\",\r\n",
    "\"Sun Salutation, a ritual performed in the early morning, combines seven different postures. The sun, the life generator, is invoked by this Yogic exercise, an easy way to keep fit.\"\r\n",
    "]\r\n",
    "stopwords = [ \"a\", \"an\", \"are\", \"be\", \"because\", \"by\", \"can\", \"for\", \"however\", \"in\", \"into\", \"is\", \"keep\", \"many\", \"not\", \"of\", \"or\", \"rather\", \"than\", \"the\", \"they\", \"this\", \"to\", \"unlike\", \"used\", \"way\", \"which\", \"with\", \"without\", \",\",\".\"]\r\n",
    "\r\n",
    "def cosine_sim(x,y):\r\n",
    "    den = np.sqrt((x**2).sum() ) * np.sqrt((y**2).sum() )\r\n",
    "    cos = (x * y).sum() / den\r\n",
    "    return cos\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set()\r\n",
    "vectors = []\r\n",
    "for i, phrase in enumerate(documents):\r\n",
    "    #print(i,phrase.lower())\r\n",
    "    documents[i] = \" \".join([p.replace(\",\",\"\").replace(\".\",\"\") for p in phrase.lower().split() if p not in stopwords])\r\n",
    "    words.update(documents[i].split())\r\n",
    "words = list(words)\r\n",
    "for phrase in documents:\r\n",
    "    p = phrase.split()\r\n",
    "    vectors.append( np.array( [ p.count(w) for w in words  ] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7689290509335256\n",
      "0.0\n",
      "0.07669649888473704\n"
     ]
    }
   ],
   "source": [
    "print(cosine_sim(vectors[0],vectors[1]))\r\n",
    "print(cosine_sim(vectors[0],vectors[2]))\r\n",
    "print(cosine_sim(vectors[1],vectors[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.76892905 0.        ]\n",
      " [0.76892905 1.         0.0766965 ]\n",
      " [0.         0.0766965  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Create the Document Term Matrix\r\n",
    "count_vectorizer = CountVectorizer(stop_words=stopwords)\r\n",
    "count_vectorizer = CountVectorizer()\r\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\r\n",
    "\r\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\r\n",
    "doc_term_matrix = sparse_matrix.todense()\r\n",
    "df = pd.DataFrame(doc_term_matrix, \r\n",
    "                  columns=count_vectorizer.get_feature_names(), \r\n",
    "                  index=['0', '1', '2'])\r\n",
    "df\r\n",
    "\r\n",
    "from sklearn.metrics.pairwise import cosine_similarity\r\n",
    "print(cosine_similarity(df, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy and classification\r\n",
    "\r\n",
    "Consider the following dataset with 8 documents d1 to d8 and features/attributes f1 to f3\r\n",
    "D\tf1\tf2\tf3\tC\r\n",
    "d1\t2\t0\t0\t1\r\n",
    "d2\t2\t0\t0\t1\r\n",
    "d3\t0\t0\t0\t2\r\n",
    "d4\t0\t1\t0\t2\r\n",
    "d5\t0\t2\t0\t3\r\n",
    "d6\t0\t2\t0\t3\r\n",
    "d7\t0\t1\t1\t3\r\n",
    "d8\t0\t2\t1\t3\r\n",
    "\r\n",
    " What  is  the  entropy  over  the  categories  for  these  training  instances  d1to  d8?   Recall  that  the  entropy  of  a  partitionTis  given  asH(T)  =−∑jP (Tj)·log2P (Tj).  \r\n",
    " UseLog2.\r\n",
    "\r\n",
    " Using the training set d1 to d8, suppose we want to construct a decisiontree for the binary classification of the category c3 (“Stochastics”),  \r\n",
    " i.e.,the tree decides whether a new document belongs to c3 category or not,using binary splits. \r\n",
    " Determine the split with the highest information gain for binary split at the root level.  \r\n",
    " Recall Information gain formula \r\n",
    " G(k, k1, k2) =H(k)− k1 /k H(k1) − k2/k * H(k2)\r\n",
    " \r\n",
    " f1≥1 f2≥1 f3≥1\r\n",
    " f1≥2 f2≥2 f3≥2\r\n",
    " f1≥3 f2≥3 f3≥3\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Heavy</th>\n      <th>Smelly</th>\n      <th>Spotted</th>\n      <th>Scales</th>\n      <th>Poisonous</th>\n    </tr>\n    <tr>\n      <th>Sample</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>b</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>c</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>d</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>e</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>f</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>g</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>h</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        Heavy  Smelly  Spotted  Scales  Poisonous\nSample                                           \na           0       0        0       0          0\nb           0       0        1       0          0\nc           1       1        0       1          0\nd           1       0        0       1          1\ne           0       1        1       0          1\nf           0       0        1       1          1\ng           0       0        0       1          1\nh           1       1        0       0          1"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "df = pd.read_csv(\"DT_2.csv\")\r\n",
    "df = df.set_index(df.columns[0])\r\n",
    "label_col = df.columns[-1]\r\n",
    "feat_cols = df.columns[0:-1]\r\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954434002924965\n",
      "0.954434002924965\n",
      "0.9512050593046015\n",
      "0.954434002924965\n",
      "0.9512050593046015\n",
      "0.954434002924965\n",
      "0.9512050593046015\n",
      "0.954434002924965\n",
      "0.9056390622295665\n"
     ]
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Heavy</th>\n      <th>Smelly</th>\n      <th>Spotted</th>\n      <th>Scales</th>\n    </tr>\n    <tr>\n      <th>Gain</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.003229</td>\n      <td>0.003229</td>\n      <td>0.003229</td>\n      <td>0.048795</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         Heavy    Smelly   Spotted    Scales\nGain                                        \n0          0.0       0.0       0.0       0.0\n1     0.003229  0.003229  0.003229  0.048795"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(d):\r\n",
    "    classes = d.unique()\r\n",
    "    n = len(d)\r\n",
    "    entropy = 0\r\n",
    "    for c in classes:\r\n",
    "        c_n = len(d[d == c])\r\n",
    "        p = c_n/n\r\n",
    "        entropy += -p * np.log2(p)\r\n",
    "    return entropy\r\n",
    "\r\n",
    "def info_gain(d,col, n_compare):\r\n",
    "    n = len(d)\r\n",
    "    node_lt = d[d[col] < n_compare] # less than\r\n",
    "    node_gt = d[d[col] >= n_compare] # greater than\r\n",
    "    n_lt = len(node_lt)\r\n",
    "    n_gt = len(node_gt)\r\n",
    "    gain =   (0 if n_lt == 0 else n_lt/n*entropy(node_lt[label_col]) )  +  (0 if n_gt == 0 else n_gt/n*entropy(node_gt[label_col]) )\r\n",
    "    return gain\r\n",
    "root_entropy = entropy(df[label_col])\r\n",
    "print(root_entropy)\r\n",
    "compare_features =  [0,1] #=[1,2,3]\r\n",
    "gain_df = pd.DataFrame(columns=feat_cols,index=compare_features)\r\n",
    "gain_df.index.name = 'Gain'\r\n",
    "#df['C'] = df['C'].apply(lambda x: 0 if x < 3 else x)\r\n",
    "for col in gain_df.columns:\r\n",
    "    for idx in gain_df.index:\r\n",
    "        gain_df[col][idx] = root_entropy - info_gain(df[[col,label_col]],col,idx)\r\n",
    "gain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\r\n",
    "\r\n",
    "Construct a decision tree given the following training data set.\r\n",
    "Outlook     Temp    Humidity    Windy   Play\r\n",
    "sunny       85      85          false   No  \r\n",
    "sunny       80      90          true    No\r\n",
    "overcast    83      78          false   Yes \r\n",
    "rain        70      96          false   Yes \r\n",
    "rain        68      80          false   Yes\r\n",
    "rain        65      70          false   Yes \r\n",
    "overcast    64      65          true    Yes \r\n",
    "sunny       72      95          false   No  \r\n",
    "sunny       69      70          false   Yes \r\n",
    "rain        75      80          false   Yes \r\n",
    "sunny       75      70          true    Yes \r\n",
    "overcast    72      90          true    Yes \r\n",
    "overcast    81      75          false   Yes \r\n",
    "rain        71      80          true    No\r\n",
    "\r\n",
    "\r\n",
    "Outlook: categorical (sunny, overcast, rain)\r\n",
    "Temperature continuous (in Fahrenheit)\r\n",
    "Humidity continuous (percentage)\r\n",
    "Windy categorical (true, false)\r\n",
    "Play categorical class/label/target (Yes, No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Outlook</th>\n      <th>Temp</th>\n      <th>Humidity</th>\n      <th>Windy</th>\n      <th>Play</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sunny</td>\n      <td>85</td>\n      <td>0.85</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sunny</td>\n      <td>80</td>\n      <td>0.90</td>\n      <td>True</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>overcast</td>\n      <td>83</td>\n      <td>0.78</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>rain</td>\n      <td>70</td>\n      <td>0.96</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>rain</td>\n      <td>68</td>\n      <td>0.80</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>rain</td>\n      <td>65</td>\n      <td>0.70</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>overcast</td>\n      <td>64</td>\n      <td>0.65</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>sunny</td>\n      <td>72</td>\n      <td>0.95</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>sunny</td>\n      <td>69</td>\n      <td>0.70</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>rain</td>\n      <td>75</td>\n      <td>0.80</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>sunny</td>\n      <td>75</td>\n      <td>0.70</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>overcast</td>\n      <td>72</td>\n      <td>0.90</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>overcast</td>\n      <td>81</td>\n      <td>0.75</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>rain</td>\n      <td>71</td>\n      <td>0.80</td>\n      <td>True</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "     Outlook  Temp  Humidity  Windy  Play\n0      sunny    85      0.85  False     0\n1      sunny    80      0.90   True     0\n2   overcast    83      0.78  False     1\n3       rain    70      0.96  False     1\n4       rain    68      0.80  False     1\n5       rain    65      0.70  False     1\n6   overcast    64      0.65   True     1\n7      sunny    72      0.95  False     0\n8      sunny    69      0.70  False     1\n9       rain    75      0.80  False     1\n10     sunny    75      0.70   True     1\n11  overcast    72      0.90   True     1\n12  overcast    81      0.75  False     1\n13      rain    71      0.80   True     0"
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Outlook', 'Temp', 'Humidity', 'Windy', 'Play']\r\n",
    "data = [\r\n",
    "        [ 'sunny',      85,     0.85,   False   , 0 ],\r\n",
    "        [ 'sunny',      80,     0.90,   True    , 0 ],\r\n",
    "        [ 'overcast',   83,     0.78,   False   , 1 ],\r\n",
    "        [ 'rain',       70,     0.96,   False   , 1 ],\r\n",
    "        [ 'rain',       68,     0.80,   False   , 1 ],\r\n",
    "        [ 'rain',       65,     0.70,   False   , 1 ],\r\n",
    "        [ 'overcast',   64,     0.65,   True    , 1 ],\r\n",
    "        [ 'sunny',      72,     0.95,   False   , 0 ],\r\n",
    "        [ 'sunny',      69,     0.70,   False   , 1 ],\r\n",
    "        [ 'rain',       75,     0.80,   False   , 1 ],\r\n",
    "        [ 'sunny',      75,     0.70,   True    , 1 ],\r\n",
    "        [ 'overcast',   72,     0.90,   True    , 1 ],\r\n",
    "        [ 'overcast',   81,     0.75,   False   , 1 ],\r\n",
    "        [ 'rain',       71,     0.80,   True    , 0 ]\r\n",
    "        ]\r\n",
    "\r\n",
    "w_df = pd.DataFrame(data=data,columns=cols)\r\n",
    "w_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\r\n",
    "    def __init__(self,data,label_col):\r\n",
    "        self.data = data\r\n",
    "        self.label_col = label_col\r\n",
    "        \r\n",
    "        self.classes = data.groupby(self.label_col)[self.label_col].count()\r\n",
    "        self.default_class = self.classes[self.classes == self.classes.max()].index[0]\r\n",
    "        self.R = [x for x in data.columns if x != label_col]  \r\n",
    "        self.root = Node(self,None,self.R,None,self.data)\r\n",
    "        self.root.ID3()\r\n",
    "        \r\n",
    "class Node:\r\n",
    "    def __init__(self,tree,parent,R,C,S):\r\n",
    "        '''\r\n",
    "            R: set of attributes\r\n",
    "            C: target attribute\r\n",
    "            S: training set\r\n",
    "            Returns a decision tree\r\n",
    "        '''\r\n",
    "        self.R = R\r\n",
    "        self.C = C\r\n",
    "        self.S = S\r\n",
    "        self.tree = tree\r\n",
    "        self.parent = parent\r\n",
    "        self.children = []\r\n",
    "        self.is_leaf = False\r\n",
    "        self.attribute = None\r\n",
    "        self.value = None\r\n",
    "        self.comparator = None\r\n",
    "        self.label = None\r\n",
    "        \r\n",
    "    def __str__(self):\r\n",
    "        node_str =  f\"{self.attribute}, {self.value}, {self.is_leaf},{self.comparator}\"\r\n",
    "        for child in self.children:\r\n",
    "            node_str += '\\n' + str(child)\r\n",
    "        return node_str\r\n",
    "            \r\n",
    "                \r\n",
    "    def entropy(self,d):\r\n",
    "        label_col = self.tree.label_col\r\n",
    "        classes = d[label_col].unique()\r\n",
    "        n = len(d)\r\n",
    "        entropy = 0\r\n",
    "        for c in classes:\r\n",
    "            c_n = len(d[d[label_col] == c])\r\n",
    "            p = c_n/n\r\n",
    "            entropy += -p * np.log2(p)\r\n",
    "        return entropy\r\n",
    "        \r\n",
    "    def info_gain(self,d,col):\r\n",
    "            label_col = self.tree.label_col\r\n",
    "            n = len(d)\r\n",
    "            root_entropy = entropy(d[label_col])\r\n",
    "            gain = 0\r\n",
    "            attrs = d[col].unique()\r\n",
    "            split_attr = None\r\n",
    "            if d[col].dtype == 'O'  or d[col].dtype == 'bool':\r\n",
    "                gain  = root_entropy\r\n",
    "                for attr in attrs:\r\n",
    "                    node_attr = d[d[col] == attr] \r\n",
    "                    n_attr = len(node_attr)\r\n",
    "                    gain -= (0 if n_attr == 0 else n_attr / n*entropy(node_attr[label_col]) )\r\n",
    "            else: # data is not categorical\r\n",
    "                for attr in attrs:\r\n",
    "                    node_lt = d[d[col] < attr] # less than\r\n",
    "                    node_gt = d[d[col] >= attr] # greater than\r\n",
    "                    n_lt = len(node_lt)\r\n",
    "                    n_gt = len(node_gt)\r\n",
    "                    g  =  root_entropy \\\r\n",
    "                        - (0 if n_lt == 0 else n_lt/n*entropy(node_lt[label_col]) ) \\\r\n",
    "                        - (0 if n_gt == 0 else n_gt/n*entropy(node_gt[label_col]) )\r\n",
    "                    if g > gain:\r\n",
    "                        gain = g\r\n",
    "                        split_attr = attr\r\n",
    "            return gain,split_attr\r\n",
    "        \r\n",
    "    def ID3(self):\r\n",
    "        label_col = self.tree.label_col\r\n",
    "        if len(self.S) == 0:\r\n",
    "            self.attribute = self.C\r\n",
    "            self.label =  self.tree.default_class\r\n",
    "            self.is_leaf = True\r\n",
    "            return\r\n",
    "        s_classes = self.S.groupby(label_col)[label_col].count()\r\n",
    "        if len(self.R) == 0:\r\n",
    "            s_classes = s_classes[s_classes == s_classes.max()]\r\n",
    "            n = s_classes[s_classes.index[0]]\r\n",
    "            self.is_leaf = True\r\n",
    "            self.attribute = self.C\r\n",
    "            self.label = s_classes.index[0]\r\n",
    "            return\r\n",
    "            node = Node(self.tree,self,None,c,None)\r\n",
    "            self.children.append(node)\r\n",
    "            \r\n",
    "        if len(s_classes) == 1:\r\n",
    "            self.is_leaf = True\r\n",
    "            self.label = s_classes.index[0]\r\n",
    "            self.attribute = self.C\r\n",
    "            return\r\n",
    "            #node = Node(self.tree,self,None,c,None)\r\n",
    "            #self.children.append(node)\r\n",
    "        gain_r = pd.DataFrame(data =[[0]*len(self.R)], columns = self.R)\r\n",
    "        split_attrs = dict()\r\n",
    "        for r in self.R:\r\n",
    "             g, split_attr = self.info_gain(self.S[[r,label_col]],r)\r\n",
    "             gain_r[r] = g\r\n",
    "             split_attrs[r] = split_attr\r\n",
    "        gain_r_t = gain_r.transpose()\r\n",
    "        max_r = gain_r_t.idxmax()[0]\r\n",
    "        r = [x for x in self.R if x != max_r]\r\n",
    "        if self.S[max_r].dtype == 'O'  or self.S[max_r].dtype == 'bool':\r\n",
    "            attrs = self.S[max_r].unique()\r\n",
    "            for attr in attrs:\r\n",
    "                node = Node(self.tree,self,r,max_r,self.S[self.S[max_r] == attr])\r\n",
    "                node.comparator == \"==\"\r\n",
    "                node.attribute == max_r\r\n",
    "                node.value == attr\r\n",
    "                self.children.append(node)\r\n",
    "                node.ID3()\r\n",
    "        else: # data is not categorical\r\n",
    "            split_attr = split_attrs[max_r]\r\n",
    "            print(split_attrs)\r\n",
    "            s_lt = self.S[self.S[max_r] < split_attr] # less than\r\n",
    "            s_gt = self.S[self.S[max_r] >= split_attr] # greater than\r\n",
    "            node_lt = Node(self.tree,self,r,max_r,s_lt)\r\n",
    "            node_lt.comparator == \"<\"\r\n",
    "            node_gt = Node(self.tree,self,r,max_r,s_gt)\r\n",
    "            node_gt.comparator == \">=\"\r\n",
    "            node_gt.value = split_attr\r\n",
    "            node_lt.value = split_attr\r\n",
    "            self.children.append(node_lt)\r\n",
    "            self.children.append(node_gt)\r\n",
    "            node_lt.ID3()\r\n",
    "            node_gt.ID3()\r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Outlook': None, 'Temp': 71, 'Humidity': 0.8, 'Windy': None}\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "classes = w_df.groupby('Play')['Play'].count()\r\n",
    "classes[classes == classes.max()].index[0]\r\n",
    "tree = Tree(w_df,'Play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Outlook</th>\n      <th>Temp</th>\n      <th>Humidity</th>\n      <th>Windy</th>\n      <th>Play</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>overcast</td>\n      <td>83</td>\n      <td>0.78</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>rain</td>\n      <td>65</td>\n      <td>0.70</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>overcast</td>\n      <td>64</td>\n      <td>0.65</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>sunny</td>\n      <td>69</td>\n      <td>0.70</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>sunny</td>\n      <td>75</td>\n      <td>0.70</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>overcast</td>\n      <td>81</td>\n      <td>0.75</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "     Outlook  Temp  Humidity  Windy  Play\n2   overcast    83      0.78  False     1\n5       rain    65      0.70  False     1\n6   overcast    64      0.65   True     1\n8      sunny    69      0.70  False     1\n10     sunny    75      0.70   True     1\n12  overcast    81      0.75  False     1"
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.root.children[0].S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None, None, False,None\n",
      "Humidity, 0.8, True,None\n",
      "None, 0.8, False,None\n",
      "Outlook, None, True,None\n",
      "None, None, False,None\n",
      "Windy, None, True,None\n",
      "Windy, None, True,None\n",
      "Outlook, None, True,None\n"
     ]
    }
   ],
   "source": [
    "print(tree.root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.7142857142857143\n",
      "Precision  0.8\n",
      "Recall  0.8\n",
      "F1  0.8000000000000002\n",
      "FPR  0.5 TPR 0.8\n"
     ]
    }
   ],
   "source": [
    "cols = ['Pred','GT']\r\n",
    "data= [\r\n",
    "    [\"Yes\", \"No\"],\r\n",
    "    [\"No\",  \"No\"],\r\n",
    "    [\"Yes\", \"Yes\"],\r\n",
    "    [\"No\",  \"Yes\"],\r\n",
    "    [\"No\",  \"Yes\"],\r\n",
    "    [\"Yes\", \"Yes\"],\r\n",
    "    [\"Yes\", \"Yes\"],\r\n",
    "    [\"No\",  \"No\"],\r\n",
    "    [\"Yes\", \"Yes\"],\r\n",
    "    [\"Yes\", \"Yes\"],\r\n",
    "    [\"Yes\", \"Yes\"],\r\n",
    "    [\"Yes\", \"Yes\"],\r\n",
    "    [\"Yes\", \"Yes\"],\r\n",
    "    [\"Yes\", \"No\"]\r\n",
    "    ]\r\n",
    "\r\n",
    "df = pd.DataFrame(data,columns=cols)\r\n",
    "df\r\n",
    "cs_cols = ['Actual','Yes',\"No\"]\r\n",
    "cs_data = [\r\n",
    "        ['Yes',0,0],\r\n",
    "        ['No',0,0]\r\n",
    "]\r\n",
    "cs = pd.DataFrame(cs_data,columns=cs_cols)\r\n",
    "cs = cs.set_index('Actual')\r\n",
    "\r\n",
    "for c_r in cs.columns:\r\n",
    "    for c_c in cs.columns:\r\n",
    "        cs[c_r][c_c] = df[ (df['Pred'] == c_r) & (df[\"GT\"] ==c_c) ].shape[0]\r\n",
    "\r\n",
    "accuracy = ( cs[\"Yes\"][\"Yes\"] + cs[\"No\"][\"No\"]) / \\\r\n",
    "    (\r\n",
    "            cs[\"Yes\"][\"Yes\"] + cs[\"Yes\"][\"No\"] + cs[\"No\"][\"Yes\"] +  cs[\"No\"][\"No\"] \r\n",
    "    )\r\n",
    "        \r\n",
    "precision = cs[\"Yes\"][\"Yes\"] / (cs[\"Yes\"][\"Yes\"] + cs[\"Yes\"][\"No\"])\r\n",
    "recall = cs[\"Yes\"][\"Yes\"] / (cs[\"Yes\"][\"Yes\"] + cs[\"No\"][\"Yes\"])\r\n",
    "f1_score = 2 * (precision * recall)/(precision + recall)\r\n",
    "\r\n",
    "TPR = cs[\"Yes\"][\"Yes\"] / (cs[\"Yes\"][\"Yes\"] + cs[\"Yes\"][\"No\"])\r\n",
    "FPR = cs[\"No\"][\"Yes\"] / (cs[\"No\"][\"No\"] + cs[\"No\"][\"Yes\"])\r\n",
    "\r\n",
    "random_probs = [0 for _ in range(len(df))]\r\n",
    "\r\n",
    "print('Accuracy ' , accuracy)\r\n",
    "print('Precision ' , precision)\r\n",
    "print('Recall ' , recall)\r\n",
    "print('F1 ' , f1_score)\r\n",
    "print('FPR ' , FPR,\"TPR\",TPR)\r\n",
    "\r\n",
    "\r\n",
    "    \r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule Based Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1], dtype=int64)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "df = pd.read_csv(\"NB_2.csv\",index_col=False)\r\n",
    "df['Outlook'] = df['Outlook'].apply(lambda x:0 if x == 'sunny' else 1 if x == 'overcast' else 2 if x == 'rain' else 0)\r\n",
    "df['Windy'] = df['Windy'].apply(lambda x:0 if x == False else 1)\r\n",
    "X = df[df.columns[0:-1]]\r\n",
    "y = df[df.columns[-1]]\r\n",
    "gnb = GaussianNB()\r\n",
    "gnb_fit = gnb.fit(X, y)\r\n",
    "pred = gnb_fit.predict([[1,70,0.65,1]])\r\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "[0.34248657 0.65751343]\n",
      "[0.34248657 0.65751343]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('NB_1.csv',index_col=False)\r\n",
    "X = df[df.columns[0:-1]]\r\n",
    "y = df[df.columns[-1]]\r\n",
    "gnb = GaussianNB()\r\n",
    "gnb_fit = gnb.fit(X, y)\r\n",
    "pred = gnb_fit.predict([[0,1,0],[1,0,1]])\r\n",
    "for p in pred:\r\n",
    "    print(p)\r\n",
    "\r\n",
    "pred = gnb_fit.predict_proba([\r\n",
    "        [0,1,0],\r\n",
    "        [1,0,1]\r\n",
    "     ])\r\n",
    "for p in pred:\r\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.06666666666666665, 0: 0.037500000000000006}\n",
      "{1: 0.06666666666666665, 0: 0.037500000000000006}\n"
     ]
    }
   ],
   "source": [
    "def cond_prob(df,vals):\r\n",
    "    label_col = df.columns[-1]\r\n",
    "    classes = df[label_col].unique()\r\n",
    "    n = len(df[label_col])\r\n",
    "    p_vals = dict()\r\n",
    "    for c in classes:\r\n",
    "        df_c = df[df[label_col] == c]\r\n",
    "        n_c = len(df_c)\r\n",
    "        p_vals[c] = n_c/n\r\n",
    "        for val in vals:\r\n",
    "            df_val = df_c[ df_c[val] == vals[val]]\r\n",
    "            n_val = len(df_val)\r\n",
    "            p_vals[c] *= n_val/n_c\r\n",
    "    return p_vals\r\n",
    "        \r\n",
    "\r\n",
    "print(cond_prob(df,{'X':0,'Y':1,'Z':0}))\r\n",
    "print(cond_prob(df,{'X':1,'Y':0,'Z':1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([784], dtype=int32)"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def relu(x):\r\n",
    "    return x if x > 0 else 0\r\n",
    "input = np.array([ 2,4])\r\n",
    "input = np.insert(input, 0, 1, axis=0)\r\n",
    "w1 = np.array([[1,1,2],[1,2,4]])\r\n",
    "w2 = np.array([[1,1,2]])\r\n",
    "h_l = (input * w1).sum(axis=1)\r\n",
    "h_l = np.vectorize(relu)(h_l)\r\n",
    "h_l = np.insert(h_l,0,1,axis=0)\r\n",
    "y =  (h_l * w2).sum(axis=1)\r\n",
    "loss = (26-y)**2\r\n",
    "loss\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 1 -3 -1]], shape=(1, 3), dtype=int32)\n",
      "tf.Tensor([[ 2 -2 -1]], shape=(1, 3), dtype=int32)\n",
      "tf.Tensor([[5]], shape=(1, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\r\n",
    "w1 = tf.constant([[1,2,3],[2,-1,2]])\r\n",
    "w2 = tf.constant([[1,1],[1,-3],[1,2]])\r\n",
    "w3 = tf.constant([[1,1],[1,-1]])\r\n",
    "w4 = tf.constant([[1],[-1]])\r\n",
    "b1 = tf.constant([1,1,0])\r\n",
    "b2 = tf.constant([0,1])\r\n",
    "b3 = tf.constant([-1,1])\r\n",
    "b4 = tf.constant([1])\r\n",
    "x = tf.constant([[-1,1]])\r\n",
    "\r\n",
    "h1 = tf.nn.relu(tf.add(tf.matmul(x,w1),b1))\r\n",
    "h2 = tf.nn.relu(tf.add(tf.matmul(h1,w2),b2))\r\n",
    "h3 = tf.nn.relu(tf.add(tf.matmul(h2,w3),b3))\r\n",
    "h4 = tf.nn.relu(tf.add(tf.matmul(h3,w4),b4))\r\n",
    "print(tf.matmul(x,w1))\r\n",
    "print(tf.add(tf.matmul(x,w1),b1))\r\n",
    "print(h4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcqUlEQVR4nO3df5BU5b3n8fd3GGAc54aYcdbyBziIXJcxEBNnyWT8sSAbhVQCuVlMiYQFwXIdLslqNu2SssIAudmKM7vhVlwHI8FoJUQwsKlQueSqWTFZbwGCEUUg6EBQcV0F5Hp3sCZm8Lt/nNPY03TPNNO/T39eVVPd53mec/rbZ7q//fRzTj/H3B0REYmuqmIHICIi+aVELyIScUr0IiIRp0QvIhJxSvQiIhFXXewAkp1//vne2NhY7DBERMrK888/f8zdG1LVlVyib2xsZNeuXcUOQ0SkrJjZa+nqNHQjIhJxSvQiIhGnRC8iEnFK9CIiEadELxWtpwfa26GhAaqqgtv29qC8GNsRyQcrtUnNmpubXWfdSCH09EBLCxw8CL29H5XX1MC4cbB9O9TVFW47Itkws+fdvTlVXUY9ejObbmYHzKzbzJamqL/ezP5gZn1mNjupbr6ZvRr+zR/aUxDJvc7OM5MzBMsHDwb1hdyOSL4M2qM3s2HAK8DngSPATmCOu+9LaNMIfAz4FrDZ3TeG5Z8AdgHNgAPPA1e7+4l0j6cevRRKQwMcOzZw/TvvFG47ItnItkc/Geh290Pu/gGwHpiV2MDdD7v7S8CHSeveBDzl7u+Gyf0pYPpZPwORPDh+PLv6XG+n0uTjuMbhw4f55Cc/mbLu9ttvZ9++fSnrStEvfvELJkyYwNSpU7PeVia/jL0YeCNh+Qjw2Qy3n2rdi5MbmdkdwB0AY8aMyXDTItmprx+4J15fX9jtVJJUxzWOHYOODti0KT/HNX784x/ndoN5tnbtWtasWcO1116b9bZK4qwbd3/I3ZvdvbmhIeVUDSI5t3hxcMA0lZoaaGsr7HYqST6Pa/T19TF37lwmTJjA7Nmzef/99wGYMmXK6elV6urquPfee/nUpz5FS0sLb7/9NhB8I7jhhhuYNGkS06ZN4/XXXwdgwYIFtLW10dLSwmWXXcYzzzzDwoULmTBhAgsWLEgZR2NjI/fccw8TJ05k8uTJdHd3Z7ytlStX8uyzz7Jo0SJisdjQd0Yok0T/JjA6YfmSsCwT2awrklexWHBWTHXS99rq6qA80/dXrrZTSbq6zkzycb29sHr10Ld94MABFi9ezP79+/nYxz5GV1fXGW1OnjxJS0sLL774Itdffz1r1qwB4Otf/zrz58/npZdeYu7cuXzjG984vc6JEyfYtm0bq1atYubMmdx9993s3buXPXv2sHv37pSxjBo1ij179rBkyRLuuuuujLe1bNkympubWbduHZ05OJqfSaLfCYw3s7FmNgK4Bdic4fafAG40s/PM7DzgxrBMpOjq6oIhgtZWqK0FOEVtbbB8NkMHudpOJcnncY3Ro0dzzTXXAPC1r32NZ5999ow2I0aM4Itf/CIAV199NYcPHwZg27Zt3HrrrQDMmzev37pf+tKXMDMmTpzIBRdcwMSJE6mqquLKK688vX6yOXPmnL7dtm1bVtvKxqCJ3t37gCUECXo/8Li77zWzlWY2E8DM/o2ZHQFuBn5kZnvDdd8FvkvwYbETWBmWiZSEujqYOjXe664mFguWzzY552o7lWKw4xbZHNcwswGXAYYPH366fNiwYfT19Q263ZEjRwJQVVV1+n58Od36iY+deH8o28pGRmP07r7F3f/a3ce5+/fCsmXuvjm8v9PdL3H3c9293t2vTFj3YXe/PPz7Sc6fgYiUnXwe13j99ddP955//vOfn9XBzNbWVtavXw/AunXruO6664YeCLBhw4bTt5/73Oey2lY2Sm4+ehGJvlgsOLsm3a+JszmuccUVV/DAAw+wcOFCmpqaaDuLT43777+f2267jc7OThoaGvjJT7Lrm544cYJJkyYxcuRIHnvssay2lQ1NgSAVb/ny4HbFCqO93fuVFXo7PT3BGSddXcE4dX190PuNxaI3DBR/rqtXf/Rc29qi81zjF1E6//zzC/J4WU+BIFJqojiJWPzc8o6O4Jxy94/OLW9pKe/nlkpdHaxYEfxq+NSp4HbFimgk+VKjRC9lJ6oJUXPmRMvhw4cL1psfjBK9lJ2oJsR8nlsulU2JXspOVBOi5syRfFGil7IT1YSYz3PLpbIp0UvZiWpC1Jw5ki9K9FJ2opoQNWdObvzwhz9kwoQJzJ07t9ihZCWX0xQr0UvZiWpC1Jw5udHV1cVTTz3FunXr+pXnY2qBfIpPU7x169ast6VEL2UnyglRc+Zk58477+TQoUPMmDGDVatWsXz5cubNm8c111zDvHnz0k5DfNVVV53+O+ecc/jd737HyZMnWbhwIZMnT+bTn/40v/rVrwB45JFH+MpXvsL06dMZP34899xzT8pYym2aYpGSo4QoqTz44INcdNFFbN26lbvvvhuAffv28dvf/pbHHnss7TTEu3fvZvfu3Xz3u9+lubmZ1tZWvve973HDDTfw3HPPsXXrVmKxGCdPnjzdfsOGDezZs4cNGzbwxhtvpIynnKYpFhEZkuXLl2NmOftbPoS5KWbOnMk555wDDDwN8auvvkosFuPxxx9n+PDhPPnkk3z/+9/nqquuYsqUKfT29p7+BjBt2jRGjRpFTU0NTU1NvPbaaykfu1SmKdakZiKSN8uXLx9Scs6lc889d9A2PT09fPWrX2XNmjVceOGFALg7mzZt4oorrujXdseOHf2mFh5omuOymqZYRCQK0k1DvHDhQm677bZ+0xLfdNNN3H///cQnfnzhhRfO+vE0TbGISIGlmob4tddeY+PGjbzyyis8/PDDQHAh8e985zvcddddTJo0iQ8//JCxY8fy61//+qwer1SmKVaiF5FISRzjTh42uvTSS3n66afPWOfDDz9Mua0f/ehHZ5QtWLCg3wXBB0r+sViM++67r1/ZI488cvp+Y2MjL7/8csq6Z555Ju12z5aGbkREIk49ehGRPMjH2TNDpR69iEjEKdGLiEScEr2ISMQp0YuIRJwSvYhIxCnRS0H19EB7OzQ0QFVVcNveXr4X9C5F2seSTKdXSsH09EBLS/8Lex87Bh0dsGlT+U8xXAq0jyUV9eilYDo7+yeguN7eoDwHs7FWPO1jSUWJXgqmq+vMBBTX2wurVxc2nijSPpZUlOilYI4fz65eBqd9LKko0UvB1NdnVy+D0z6WVJTopWAWL4aamtR1NTXQ1lbYeKJI+1hSySjRm9l0MztgZt1mtjRF/Ugz2xDW7zCzxrB8uJk9amZ7zGy/mX07x/FLGYnFYNw4qE4616u6OijPwTWQK572saQyaKI3s2HAA8AMoAmYY2ZNSc0WASfc/XJgFRCfgPlmYKS7TwSuBv5j/ENAKk9dXXB6X2sr1NYCnKK2NljWaX+5oX0sqWTSo58MdLv7IXf/AFgPzEpqMwt4NLy/EZhmwQUSHTjXzKqBc4APgH/JSeRSlurqYOrUeM+ymlgsWFYCyh3tY0mWSaK/GHgjYflIWJayjbv3Ae8B9QRJ/yTwFvA68N/c/d3kBzCzO8xsl5ntOnr06Fk/CRERSS/fB2MnA6eAi4CxwH82s8uSG7n7Q+7e7O7NDQ0NeQ5JRKSyZJLo3wRGJyxfEpalbBMO04wCjgO3Av/o7n9x93eAfwKasw1aREQyl0mi3wmMN7OxZjYCuAXYnNRmMzA/vD8beNrdnWC45gYAMzsXaAH+mIvARUQkM4Mm+nDMfQnwBLAfeNzd95rZSjObGTZbC9SbWTfwTSB+CuYDQJ2Z7SX4wPiJu7+U6ychIiLpZTR7pbtvAbYklS1LuN9LcCpl8no9qcpFRKRw9MtYEZGIU6IXEYk4JXoRkYhTohcRiTglehGRiFOiFxGJOCV6EZGIU6IXEYk4JXoRkYhTohcRiTglehGRiFOiFxGJOCV6EUmppwfa26GhAaqqgtv29qBcyosSvWREb/rK0tMDLS3Q0QHHjoF7cNvREZTr/15elOhlUHrTV57OTjh4EHp7+5f39gblnZ3FiUuGRoleBqU3feXp6jrz/x3X2wurVxc2HsmOEr0MSm/6ynP8eHb1UlqU6GVQetNXnvr67OqltCjRy6D0pq88ixdDTU3qupoaaGsrbDySHSV6GZTe9JUnFoNx46A66arS1dVBeSxWnLhkaJToZVB601eeujrYvh1aW6G2FuAUtbXB8vbtQb2UDyV6GZTe9JWprg6mTo1/kFcTiwXL+n+XHyV6yYje9CLlS4leRCTilOhFRCJOiV5EJOKU6EVEIk6JXkQk4pToRUQiToleRCTiMkr0ZjbdzA6YWbeZLU1RP9LMNoT1O8ysMaFukpltM7O9ZrbHzNL8mF5ERPJh0ERvZsOAB4AZQBMwx8yakpotAk64++XAKuC+cN1q4GfAne5+JTAF+EvOohcRkUFl0qOfDHS7+yF3/wBYD8xKajMLeDS8vxGYZmYG3Ai85O4vArj7cXc/lZvQRUQkE5kk+ouBNxKWj4RlKdu4ex/wHlAP/DXgZvaEmf3BzO5J9QBmdoeZ7TKzXUePHj3b5yAiIgPI98HYauBaYG54+zdmNi25kbs/5O7N7t7c0NCQ55BERCpLJon+TWB0wvIlYVnKNuG4/CjgOEHv//fufszd3we2AJ/JNmgREclcJol+JzDezMaa2QjgFmBzUpvNwPzw/mzgaXd34AlgopnVhh8A/xbYl5vQRUQkE9WDNXD3PjNbQpC0hwEPu/teM1sJ7HL3zcBa4Kdm1g28S/BhgLufMLMfEHxYOLDF3f8hT89FRERSGDTRA7j7FoJhl8SyZQn3e4Gb06z7M4JTLEVEpAj0y1gRkYhTohcRiTglehGRiFOiF5G86umB9nZoaICqquC2vT0ol8LI6GCsiMhQ9PRASwscPAi9vUHZsWPQ0QGbNsH27brAfCGoRx9x6k1JMXV29k/ycb29QXlnZ3HiqjRK9BEW7011dAS9KPePelMtLUr2kn9dXWcm+bjeXli9urDxVCol+ghTb0qK7fjx7OolN5ToI0y9KSm2+vrs6iU3lOgjTL0pKbbFi6EmzTXlamqgra2w8VQqJfoIU29Kii0Wg3HjoDrp/L7q6qA8FitOXJVGiT7C1JuSYqurC06hbG2F2lqAU9TWBss6tbJwlOgjTL0pKQV1dTB1avz1Vk0sFiwryReOEn2EqTclIqBEH3nqTYmIEr2ISMQp0YuIRJwSvYhIxCnRi4hEnBK9iEjEKdGLiEScEr2ISMQp0YuIRJwSvYhIxCnRi4hEnBK9iEjEKdGLiEScEr2ISMQp0YuIRJwSvYhIxGWU6M1supkdMLNuM1uaon6kmW0I63eYWWNS/Rgz6zGzb+UobhERydCgid7MhgEPADOAJmCOmTUlNVsEnHD3y4FVwH1J9T8AfpN9uCJSqXp6oL0dGhqgqiq4bW8PymVgmfToJwPd7n7I3T8A1gOzktrMAh4N728EppmZAZjZl4E/AXtzErGIVJyeHmhpgY4OOHYM3IPbjo6gXMl+YJkk+ouBNxKWj4RlKdu4ex/wHlBvZnXAfwFWDPQAZnaHme0ys11Hjx7NNHYRqRCdnXDwIPT29i/v7Q3KOzuLE1e5yPfB2OXAKncf8PPW3R9y92Z3b25oaMhzSOVBX1NFPtLVdWaSj+vthdWrCxtPuanOoM2bwOiE5UvCslRtjphZNTAKOA58FphtZh3Ax4EPzazX3f9HtoFHWfxramIPJv41ddMm2L5dF/eWynL8eHb1lS6THv1OYLyZjTWzEcAtwOakNpuB+eH92cDTHrjO3RvdvRH4e+C/KskPTl9TRfqrr8+uvtINmujDMfclwBPAfuBxd99rZivNbGbYbC3BmHw38E3gjFMwJXP6mirS3+LFUFOTuq6mBtraChtPuclk6AZ33wJsSSpblnC/F7h5kG0sH0J8FUlfU0X6i8WCYcsDB6Cv76Py6moYNy6ol/T0y9gSpK+pIv3V1QXHplpbobYW4BS1tcGyjlkNTom+BOlrqsiZ6upg6tR4772aWCxYVpIfnBJ9CYrFgq+j1UkDa/qaKiJDoURfgvQ1VURySYm+ROlrqojkihK9iEjEKdGLiEScEr2ISMQp0YuIRJwSvYhIxCnRi4hEnBK9iEjEKdGLiEScEr2ISMQp0YuIRJwSvYhIxCnRi0hF6emB9nZoaICqquC2vT0oj6qMrjAlIhIFPT3Q0tL/mszHjkFHR3AFq6jODqsevYhUjM7O/kk+rrc3KO/sLE5c+aZELyIVo6vrzCQf19sLq1cXNp5CUaLPsUoc/xMpF8ePZ1dfrpTocyg+/tfREYz7uX80/tfSomQvUmz19dnVlysl+hyq1PE/kXKxeDHU1KSuq6mBtrbCxlMoSvQ5VKnjfyLlIhaDceOgOul8w+rqoDy4dGf0KNHnUKWO/4mUi7q64BTK1laorQU4RW1tsBzVUytBiT6nKnX8T6Sc1NXB1Knx3ns1sViwHNUkD0r0OVWp438iUtqU6HOoUsf/RKS0KdHnUKWO/4lIaVOiz7FKHP8TkdKWUaI3s+lmdsDMus1saYr6kWa2IazfYWaNYfnnzex5M9sT3t6Q4/hFRGQQgyZ6MxsGPADMAJqAOWbWlNRsEXDC3S8HVgH3heXHgC+5+0RgPvDTXAUuIiKZyaRHPxnodvdD7v4BsB6YldRmFvBoeH8jMM3MzN1fcPf/E5bvBc4xs5G5CFxERDKTSaK/GHgjYflIWJayjbv3Ae8ByWeN/3vgD+7+56GFKiIiQ1GQC4+Y2ZUEwzk3pqm/A7gDYMyYMYUISUSkYmTSo38TGJ2wfElYlrKNmVUDo4Dj4fIlwC+B/+DuB1M9gLs/5O7N7t7c0NBwds9ARKQIymlK8kwS/U5gvJmNNbMRwC3A5qQ2mwkOtgLMBp52dzezjwP/ACx193/KUcwiIkVVblOSD5rowzH3JcATwH7gcXffa2YrzWxm2GwtUG9m3cA3gfgpmEuAy4FlZrY7/PtXOX8WIiIFVG5Tkmc0Ru/uW4AtSWXLEu73AjenWO/vgL/LMkYRkZKSyZTkK1YUNqaB6JexoXIabxOR4iq3KcmV6Cm/8TYRKa5ym5JciZ7yG28TkeIqtynJlejRJQBF5OyU25TkSvSU33ibiBRXuU1JrkRP+Y23iUjxldOU5Er0lN94m4jI2VCip/zG20REzoYSPeU33iYicjaU6EPlNN4mItFRiB9rFmSaYhEROVP8x5qJv+OJ/1hz06bcjSioRy8iUiSF+rFmJBK95qkRkXJUqB9rlv3QTaG++oiI5FqhfqxZ9j16zVMjIuWqUD/WLPtEr3lqRKRcFerHmmWf6DVPjYiUq0L9WLPsE73mqRGRclWoH2uWfaLXPDUiUs4K8WPNsk/0mqdGRGRgZZ/oNU+NiMjAyj7Rg+apEREZSCQSvYiIpKdELyIScUr0IiIRp0QvIhJxSvQiIhGnRC8iEnFK9CIiEadELyIScUr0IiIRl1GiN7PpZnbAzLrNbGmK+pFmtiGs32FmjQl13w7LD5jZTTmMXUREMjBoojezYcADwAygCZhjZk1JzRYBJ9z9cmAVcF+4bhNwC3AlMB3oCrcnIiIFkkmPfjLQ7e6H3P0DYD0wK6nNLODR8P5GYJqZWVi+3t3/7O5/ArrD7YmISIFkcnHwi4E3EpaPAJ9N18bd+8zsPaA+LN+etO7FyQ9gZncAdwCMGTMm09j7mTIluD18uP30/WJsQ9vRdkphO6UUi7ZTuO2kY+4+cAOz2cB0d789XJ4HfNbdlyS0eTlscyRcPkjwYbAc2O7uPwvL1wK/cfeN6R6vubnZd+3aldWTEhGpNGb2vLs3p6rLZOjmTWB0wvIlYVnKNmZWDYwCjme4roiI5FEmiX4nMN7MxprZCIKDq5uT2mwG5of3ZwNPe/BVYTNwS3hWzlhgPPBcbkIXEZFMDDpGH465LwGeAIYBD7v7XjNbCexy983AWuCnZtYNvEvwYUDY7nFgH9AH/K27n8rTcxERkRQGHaMvNI3Ri4icvWzH6EVEpIwp0YuIRJwSvYhIxCnRi4hEXMkdjDWzo8BreXyI84Fjedx+PijmwlDM+Vdu8UL5xHypuzekqii5RJ9vZrYr3ZHpUqWYC0Mx51+5xQvlGXMyDd2IiEScEr2ISMRVYqJ/qNgBDIFiLgzFnH/lFi+UZ8z9VNwYvYhIpanEHr2ISEVRohcRibjIJHoze9jM3gkvghIv22Bmu8O/w2a2O826h81sT9iuYDOqmdloM9tqZvvMbK+Z/aew/BNm9pSZvRrenpdm/flhm1fNbH6qNgWMudPM/mhmL5nZL83s42nWL+i+HiDe5Wb2ZsLr4wtp1p8eXti+28yW5jveQWIu2dezmdWY2XNm9mIY84qwfKyZ7Qj334ZwqvNU6387bHPAzG4qcszrwjheDvPK8DTrn0r4fyRP3V5a3D0Sf8D1wGeAl9PU/3dgWZq6w8D5RYj5QuAz4f2/Al4huAB7B7A0LF8K3Jdi3U8Ah8Lb88L75xUx5huB6rD8vlQxF2NfDxDvcuBbg6w7DDgIXAaMAF4EmooVc1Kbkno9AwbUhfeHAzuAFuBx4Jaw/EGgLcW6TeG+HQmMDff5sCLG/IWwzoDHUsUcrtNTyH2czV9kevTu/nuCufDPEF6o/KsE/7SS4e5vufsfwvv/D9hPcE3dxIutPwp8OcXqNwFPufu77n4CeAqYXqyY3f1Jd+8Lm20nuJpY0Q2wjzMxGeh290Pu/gGwnuB/k1eDxVyKr2cP9ISLw8M/B24A4pcOTfdangWsd/c/u/ufgG6CfZ9X6WJ29y1hnRNcKKkkXsvZiEyiH8R1wNvu/mqaegeeNLPnLbhQecGZWSPwaYJexQXu/lZY9X+BC1Kskuqi7ZkmsJxIijnRQuA3aVYr2r5OEe+ScKjp4TTDY6W6j0vy9Wxmw8LhpHcIOh4HgX9O6ACk239F28/JMbv7joS64cA84B/TrF5jZrvMbLuZfTnvwWahUhL9HAbu/Vzr7p8BZgB/a2bXFyasgJnVAZuAu9z9XxLrwl5FyZ0Dmy5mM7uX4Gpi69KsWpR9nSLe1cA44CrgLYKhkJIywOuiJF/P7n7K3a8i6AFPBv51IR43G8kxm9knE6q7gN+7+/9Os/qlHkyNcCvw92Y2Lr/RDl3kE70FFyv/CrAhXRt3fzO8fQf4JQX42hgX9ho2Aevc/X+GxW+b2YVh/YUEvY1kRbvwepqYMbMFwBeBueEH1BmKsa9Txevub4dv8g+BNWniKMV9XNKv5/Bx/xnYCnwO+HgYM6Tff0Xbz3EJMU8HMLN2oAH45gDrxPfzIeAZgm9eJSnyiR74d8Af3f1IqkozO9fM/ip+n+Cg4sup2uZaONa6Ftjv7j9IqEq82Pp84FcpVn8CuNHMzguHHW4My/IqXcxmNh24B5jp7u+nWbfg+3qAeC9MaPY3aeLYCYwPzxwZQXAt5LyfXTHA6wJK9PVsZg0WnmllZucAnyc4trAVmB02S/da3gzcYmYjzWwsMJ5gbLwYMf/RzG4nOAY2J+wIpFr3PDMbGd4/H7iG4NrYpanYR4Nz9UfwVfYt4C8EY3yLwvJHgDuT2l4EbAnvX0ZwxP9FYC9wbwFjvpZgWOYlYHf49wWgHvhfwKvAb4FPhO2bgR8nrL+Q4MBVN3BbkWPuJhhnjZc9WAr7eoB4fwrsCcs3Axcmxxsuf4HgrJeDhXptpIu5lF/PwCTghTDmlwnPCArjeS58ffwCGBmWzwRWJqx/b7iPDwAzihxzXxhLfN/Hy0+//4DW8PXzYni7qBAxD/VPUyCIiERcJQzdiIhUNCV6EZGIU6IXEYk4JXoRkYhTohcRiTglehGRiFOiFxGJuP8PGQxy0bZ0H2gAAAAASUVORK5CYII=\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "array([0.00886767, 0.01543631, 0.02491475, 0.03737212, 0.05220233,\n       0.06802122, 0.08280844, 0.09430961, 0.10059692, 0.10059692,\n       0.09438723, 0.08315066, 0.06881434, 0.05352226, 0.03913456,\n       0.02690501, 0.01739314, 0.0105723 ])"
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\r\n",
    "import random\r\n",
    "import sys\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "n = 32\r\n",
    "vals = []\r\n",
    "for i in range(n):\r\n",
    "    rnd = random.randint(0,sys.maxsize)\r\n",
    "    vals.append(rnd)\r\n",
    "vals\r\n",
    "\r\n",
    "from scipy.stats import binom\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "fig, ax = plt.subplots(1, 1)\r\n",
    "n, p = 64, 0.4\r\n",
    "mean, var, skew, kurt = binom.stats(n, p, moments='mvsk')\r\n",
    "\r\n",
    "x = np.arange(binom.ppf(0.01, n, p), binom.ppf(0.99, n, p))\r\n",
    "ax.plot(x, binom.pmf(x, n, p), 'bo', ms=8, label='binom pmf')\r\n",
    "ax.vlines(x, 0, binom.pmf(x, n, p), colors='b', lw=5, alpha=0.5)\r\n",
    "\r\n",
    "rv = binom(n, p)\r\n",
    "ax.vlines(x, 0, rv.pmf(x), colors='k', linestyles='-', lw=1,label='frozen pmf')\r\n",
    "ax.legend(loc='best', frameon=False)\r\n",
    "plt.show()\r\n",
    "rv.pmf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "5.0"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##See for further information https://math.stackexchange.com/questions/3579001/prove-the-maximum-value-of-entropy-function\r\n",
    "\r\n",
    "factor = 0\r\n",
    "n = 32\r\n",
    "x  = [1/n for i in range(1,n+1)]\r\n",
    "sum(x)\r\n",
    "h = 0\r\n",
    "for i in x:\r\n",
    "    h += -i * (0 if i == 0 else math.log2(i)) \r\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 1)           10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\r\n",
    "\r\n",
    "from tensorflow.keras import datasets, layers, models\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "model = models.Sequential()\r\n",
    "model.add(layers.Conv2D(1, (3, 3), activation='relu', input_shape=(5, 5, 1)))\r\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\r\n",
    "#model.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\r\n",
    "#model.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
    "#model.add(layers.Flatten())\r\n",
    "#model.add(layers.Dense(64, activation='relu'))\r\n",
    "#model.add(layers.Dense(10))\r\n",
    "model.summary()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\r\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
    "              metrics=['accuracy'])\r\n",
    "\r\n",
    "history = model.fit(train_images, train_labels, epochs=10, \r\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-315-380e5cbc2e6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_roc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  \r\n",
    "from sklearn import datasets, metrics, model_selection, svm\r\n",
    "X, y = datasets.make_classification(random_state=0)\r\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state=0)\r\n",
    "clf = svm.SVC(random_state=0)\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "SVC(random_state=0)\r\n",
    "metrics.plot_roc_curve(clf, X_test, y_test)  \r\n",
    "plt.show()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.5555555555555556\n",
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "docs = [\r\n",
    "'Peter Piper picked a peck of pickled peppers',\r\n",
    "'Peter picked a big peck of pickled peppers',\r\n",
    "'Peter Piper picked a peck of mixed peppers']\r\n",
    "\r\n",
    "S = []\r\n",
    "shingles = []\r\n",
    "for d in docs:\r\n",
    "    d = d.lower()\r\n",
    "    d_shingle = []\r\n",
    "    words = d.split(' ')\r\n",
    "    #words = d.replace(' ', '')\r\n",
    "    n_words = len(words)\r\n",
    "    for i in range(n_words):\r\n",
    "        if i  < n_words-1:\r\n",
    "            n_gram = words[i] + words[i+1]\r\n",
    "            if n_gram not in S:\r\n",
    "                S.append(n_gram)\r\n",
    "            d_shingle.append(n_gram)\r\n",
    "    shingles.append(set(d_shingle))\r\n",
    "\r\n",
    "def jaccard (d1,d2):\r\n",
    "    return len( d1.intersection(d2)) / len(d1.union(d2))\r\n",
    "\r\n",
    "print(jaccard(shingles[0],shingles[1]))\r\n",
    "print(jaccard(shingles[0],shingles[2]))\r\n",
    "print(jaccard(shingles[1],shingles[2]))\r\n",
    "\r\n",
    "data = [ [int(s in shingle)  for s in S] for shingle in shingles ]\r\n",
    "df = pd.DataFrame(data = data, columns = S)\r\n",
    "doc_labels = ['S'+ str(i) for i in range(len(df))]\r\n",
    "df['Docs'] = doc_labels\r\n",
    "df = df.set_index('Docs')\r\n",
    "df = df.T\r\n",
    "df\r\n",
    "perms = ['Perm1', 'Perm2']\r\n",
    "df[perms[0]] = [(8 * x + 9)%47  for x in range(1,len(df)+1)]\r\n",
    "df[perms[1]] = [(2 * x + 4)%47  for x in range(1,len(df)+1)]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Docs</th>\n      <th>S0</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>Perm1</th>\n      <th>Perm2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>peterpiper</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>17</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>piperpicked</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>25</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>pickeda</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>33</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>apeck</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>41</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>peckof</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>ofpickled</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>pickledpeppers</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>18</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>peterpicked</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>26</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>abig</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>34</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>bigpeck</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>42</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>ofmixed</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>mixedpeppers</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>11</td>\n      <td>28</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "Docs            S0  S1  S2  Perm1  Perm2\npeterpiper       1   0   1     17      6\npiperpicked      1   0   1     25      8\npickeda          1   1   1     33     10\napeck            1   0   1     41     12\npeckof           1   1   1      2     14\nofpickled        1   1   0     10     16\npickledpeppers   1   1   0     18     18\npeterpicked      0   1   0     26     20\nabig             0   1   0     34     22\nbigpeck          0   1   0     42     24\nofmixed          0   0   1      3     26\nmixedpeppers     0   0   1     11     28"
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{2, 6}, {2, 10}, {2, 6}]\n",
      "0.3333333333333333\n",
      "1.0\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "signatures = []\r\n",
    "for label in doc_labels:\r\n",
    "    signature = []\r\n",
    "    for perm in perms:\r\n",
    "        for i in df[perm].sort_values():\r\n",
    "            cell_value = df[label][df.index[df[perm] == i]][0]\r\n",
    "            if(cell_value == 1):\r\n",
    "                signature.append(i)\r\n",
    "                break\r\n",
    "    signatures.append(set(signature))\r\n",
    "print(signatures)\r\n",
    "print(jaccard(signatures[0],signatures[1]))\r\n",
    "print(jaccard(signatures[0],signatures[2]))\r\n",
    "print(jaccard(signatures[1],signatures[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "name": "python389jvsc74a57bd081f787511eac16c0f08bc3f79587249acbad11b06be2962b133dcdfa41c30393"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}